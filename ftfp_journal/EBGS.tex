%% NEW VERSION
% marek Thu Nov 29 12:16:01 PST 2012
%          still a lot of work needed. 
% marek Tue Dec  4 12:54:24 PST 2012
% marek Mon Dec 10 18:48:31 PST 2012


\section{Algorithm~{\EBGS} with Ratio $1.575$}\label{sec: 1.575-approximation}

In this section we give our main result, a $1.575$-approximation
algorithm for $\FTFP$, where $1.575$ is the value of $\min_{\gamma\geq
  1}\max\{\gamma, 1+2/e^\gamma, \frac{1/e+1/e^\gamma}{1-1/\gamma}\}$,
rounded to three decimal digits. This matches the ratio of the best
known LP-rounding algorithm for UFL by
Byrka~{\etal}~\cite{ByrkaGS10}. 

Recall that in Section~\ref{sec: 1.736-approximation} we showed how to
compute an integral solution with facility cost bounded by $F^\ast$
and connection cost bounded by $C^\ast + 2/e\cdot\LP^\ast$. A natural
idea is to balance these two costs, by reducing the connection cost at
the expense of a slight increase in the facility cost. One way to do
this would be to increase the probability of opening facilities, from
$\bary_{\mu}$ (used in Algorithm~{\ECHS}) to, say,
$\gamma\bary_{\mu}$, for some $\gamma > 1$. This increases the
expected facility cost by a factor of $\gamma$ but, as it turns out,
it also reduces the probability that an indirect connection occurs for
a non-primary demand to $1/e^\gamma$ (from the previous value
$1/e$). Moreover, for each primary demand $\kappa$, the new algorithm
will select a facility from the nearest facilities $\mu$ in
$\wbarN(\kappa)$ such that the total connection value $\barx_{\mu\nu}$
sum up to $1/\gamma$, instead of $1$. It is easily seen that this will
improve the estimate on connection cost for primary demands.  These
two changes, along with a more refined analysis, are the essence of
the approach in~\cite{ByrkaGS10}, expressed in our terminology.

Our approach can be thought of as a combination of the above ideas
with the techniques of demand reduction and
adaptive partitioning that we introduced earlier. However, our
adaptive partitioning technique needs to be carefully modified,
because now we will be using a more intricate neighborhood structure,
with the neighborhood of each demand divided into two disjoint parts,
and with some restrictions on how parts from different demands can overlap.

We begin by describing properties that our partitioned fractional
solution $(\barbfx,\barbfy)$ needs to satisfy. As mentioned earlier,
the neighborhood $\wbarN(\nu)$ of each demand $\nu$ will be divided
into two disjoint parts.  The first part, called the \emph{close
  neighborhood} and denoted $\wbarclsnb(\nu)$, contains the facilities
in $\wbarN(\nu)$ nearest to $\nu$ with the total connection value
equal $1/\gamma$, that is $\sum_{\mu\in\wbarclsnb(\nu)} \barx_{\mu\nu}
= 1/\gamma$.  The second part, called the \emph{far neighborhood} and
denoted $\wbarfarnb(\nu)$, contains the remaining facilities in
$\wbarN(\nu)$ (so $\sum_{\mu\in\wbarfarnb(\nu)} \barx_{\mu\nu} = 1-1/\gamma$).  We
restate these definitions formally below in Property~(NB).  Recall
that for any set $A$ of facilities and a demand $\nu$, by
$D(A,\nu)$ we denote the average distance between $\nu$ and the
facilities in $A$, that is $D(A,\nu) =\sum_{\mu\in A}
d_{\mu\nu}\bary_{\mu}/\sum_{\mu\in A} \bary_{\mu}$.  We will use
notations $\clsdist(\nu)=D(\wbarclsnb(\nu),\nu)$ and
$\fardist(\nu)=D(\wbarfarnb(\nu),\nu)$ for the average distances from
$\nu$ to its close and far neighborhoods, respectively.  By the
definition of these sets and the completeness property (CO), these
distances can be expressed as
%
\begin{equation*}
\clsdist(\nu)=\gamma\sum_{\mu\in\wbarclsnb(\nu)}
			d_{\mu\nu}\barx_{\mu\nu} \quad\text{and}\quad
\fardist(\nu)=\frac{\gamma}{\gamma-1}\sum_{\mu\in\wbarfarnb(\nu)}
d_{\mu\nu}\barx_{\mu\nu}. 
\end{equation*}
%
We will also use
notation $\clsmax(\nu)=\max_{\mu\in\wbarclsnb(\nu)} d_{\mu\nu}$ for
the maximum distance from $\nu$ to its close neighborhood.

Our partitioned solution $(\barbfx,\barbfy)$ must satisfy the same
partitioning and completeness properties as before, namely properties
(PS) and (CO) in Section~\ref{sec: adaptive partitioning}.  In
addition, it must satisfy a new neighborhood property (NB) and modified
properties (PD') and (SI'), listed below.

\begin{description}
	
      \renewcommand{\theenumii}{(\alph{enumii})}
      \renewcommand{\labelenumii}{\theenumii}

\item{(NB)} \label{NB}
	\emph{Neighborhoods.}
	For each demand $\nu \in \demandset$, its neighborhood is divided into \emph{close} and
	\emph{far} neighborhood, that is $\wbarN(\nu) = \wbarclsnb(\nu) \cup \wbarfarnb(\nu)$, where
	%
	\begin{itemize}
	\item $\wbarclsnb(\nu) \cap \wbarfarnb(\nu) = \emptyset$,
	\item $\sum_{\mu\in\wbarclsnb(\nu)} \barx_{\mu\nu} =1/\gamma$, and 
	\item if $\mu\in \wbarclsnb(\nu)$ and $\mu'\in \wbarfarnb(\nu)$ 
				then $d_{\mu\nu}\le d_{\mu'\nu}$.   
	\end{itemize}
	%
	Note that the first two conditions, together with
        (PS.\ref{PS:one}), implies that $\sum_{\mu\in\wbarfarnb(\nu)}
        \barx_{\mu\nu} =1-1/\gamma$.

\item{(PD')} \emph{Primary demands.}
	Primary demands satisfy the following conditions:

	\begin{enumerate}
		
	\item\label{PD1:disjoint}  For any two different primary demands $\kappa,\kappa'\in P$ we have
				$\wbarclsnb(\kappa)\cap \wbarclsnb(\kappa') = \emptyset$.

	\item \label{PD1:yi} For each site $i\in\sitesset$, 
		$ \sum_{\kappa\in P}\sum_{\mu\in
                  i\cap\wbarclsnb(\kappa)}\barx_{\mu\kappa} \leq
                y_i^\ast$. In the summation, as before, we overload notation $i$ to stand for the set of
						facilities opened on site $i$.
		
	\item \label{PD1:assign} Each demand $\nu\in\demandset$ is assigned
        to one primary demand $\kappa\in P$ such that

  			\begin{enumerate}
	
				\item \label{PD1:assign:overlap} $\wbarclsnb(\nu) \cap \wbarclsnb(\kappa) \neq \emptyset$, and
				%
				\item \label{PD1:assign:cost}
          $\clsdist(\nu)+\clsmax(\nu) \geq
          \clsdist(\kappa)+\clsmax(\kappa)$.
          %
			\end{enumerate}

	\end{enumerate}
	
\item{(SI')} \emph{Siblings}. For any pair $\nu,\nu'\in\demandset$ of different siblings we have
  \begin{enumerate}

	\item \label{SI1:siblings disjoint}
		  $\wbarN(\nu)\cap \wbarN(\nu') = \emptyset$.
		
	\item \label{SI1:primary disjoint} If $\nu$ is assigned to a primary demand $\kappa$ then
 		$\wbarN(\nu')\cap \wbarclsnb(\kappa) = \emptyset$. In particular, by Property~(PD'.\ref{PD1:assign:overlap}),
		this implies that different sibling demands are assigned to different primary demands, since $\wbarclsnb(\nu')$ is a subset of $\wbarN(\nu')$.

	\end{enumerate}
	
\end{description}

%%%%%%%%%%%%%%%%%

\paragraph{Modified adaptive partitioning.}
To obtain a fractional solution with the above properties, we employ a
modified adaptive partitioning algorithm. As in Section~\ref{sec:
  adaptive partitioning}, we have two phases.  In Phase~1 we split
clients into demands and create facilities on sites, while in Phase~2
we augment each demand's connection values $\barx_{\mu\nu}$ by setting
$\barx_{\mu\nu}$ from $0$ to $\bary_{\mu}$, so that the total value is
$1$. As the partitioning algorithm proceeds, for any demand $\nu$,
$\wbarN(\nu)$ denotes the set of facilities with $\barx_{\mu\nu} > 0$,
hence $\wbarN(\nu)$ are dynamic sets which get fixed once the
partitioning algorithm concludes both Phase 1 and Phase 2. On the
other hand, $\wbarclsnb(\nu)$ and $\wbarfarnb(\nu)$ refer to the close
and far neighborhoods once $\wbarN(\nu)$ is fixed.

Similar to the algorithm in Section~\ref{sec: adaptive partitioning},
Phase~1 runs in iterations. Fix some iteration and consider any client
$j$.  As before, $\wtildeN(j)$ is the neighborhood of $j$ with respect
to the yet unpartitioned solution, namely the set of facilities $\mu$
such that $\tildex_{\mu j}>0$. Order the facilities in this set as
$\wtildeN(j) = \braced{\mu_1,...,\mu_q}$ with non-decreasing distance
from $j$, that is $d_{\mu_1 j} \leq d_{\mu_2 j} \leq \ldots \leq
d_{\mu_q j}$, where $q = |\wtildeN(j)|$. Without loss of generality,
there is an index $l$ for which $\sum_{s=1}^l \tildex_{\mu_s j} =
1/\gamma$, since we can always split one facility to achieve
this. Then we define $\wtildeclsnb(j) = \braced{\mu_1,...,\mu_l}$. In
case of ties, we use a tie-breaking rule that is explained in the
proof of Lemma~\ref{lem: PD1: primary overlap} (the only place where
the rule is needed). We also use notation
%
\begin{equation*}
\tcccls(j) =  D(\wtildeclsnb(j), j) = \gamma\sum_{\mu\in\wtildeclsnb(j)} d_{\mu j} \tildex_{\mu j}
			\quad\textrm{ and }\quad
 \dmaxcls(j) = \max_{\mu \in \wtildeclsnb(j)} d_{\mu j}. 
\end{equation*}
%

When the iteration starts, we first find a not-yet-exhausted client
$p$ that minimizes the value of $\tcccls(p) + \dmaxcls(p)$ and create
a new demand $\nu$ for $p$.  Now we have two cases:
%
\begin{description}
%
\item{\mycase{1}} $\wtildeclsnb(p) \cap \wbarN(\kappa)\neq\emptyset$
  for some existing primary demand $\kappa\in P$.  In this case we
  assign $\nu$ to $\kappa$. As before, if there are multiple such
  $\kappa$, we pick any of them. We also fix $\barx_{\mu \nu} \assign
  \tildex_{\mu p}$ and $\tildex_{\mu p}\assign 0$ for each $\mu \in
  \wtildeN(p)\cap \wbarN(\kappa)$. Note that, as before, although we
  check for overlap between $\wtildeclsnb(p)$ and $\wbarN(\kappa)$,
  the facilities we actually move into $\wbarN(\nu)$ include all
  facilities in the intersection of $\wtildeN(p)$, a bigger set, with
  $\wbarN(\kappa)$.

  At this time, the total connection value $\barx_{\mu\nu}$ between
  $\nu$ and $\mu\in \wbarN(\nu)$ is at most $1/\gamma$ since the sum
  of $\bary_{\mu}$ for all $\mu \in \wbarN(\kappa)$ is $1/\gamma$ and
  we have $\wbarN(\nu) \subseteq \wbarN(\kappa)$ at this point. Later
  in Phase 2 we will add additional facilities from $\wtildeN(p)$ to
  $\wbarN(\nu)$ to make $\nu$'s total connection value to
  $\wbarN(\nu)$ equal to $1$.

%
\item{\mycase{2}} $\wtildeclsnb(p) \cap \wbarN(\kappa) = \emptyset$
  for all existing primary demands $\kappa\in P$.  In this case we
  make $\nu$ a primary demand (that is, add it to $P$) and assign it
  to itself.  We then move the facilities from $\wtildeclsnb(p)$ to
  $\wbarN(\nu)$, that is for $\mu \in \wtildeclsnb(p)$ we set
  $\barx_{\mu \nu}\assign \tildex_{\mu p}$ and $\tildex_{\mu p}\set
  0$.

  It is easy to see that the total connection value of $\nu$ to
  $\wbarN(\nu)$ is now exactly $1/\gamma$.  Moreover, facilities
  remaining in $\wtildeN(p)$ are all farther away from $\nu$ than
  those in $\wbarN(\nu)$. As we add only facilities from $\wtildeN(p)$
  to $\wbarN(\nu)$ in Phase~2, the final $\wbarclsnb(\nu)$ contains
  the same set of facilities as $\wbarN(\nu)$ at this point, taking
  into account of possible facility split.
%
\end{description}
%
Once all clients are exhausted, that is, each client $j$ has $r_j$
demands created, Phase~1 concludes. We then run Phase~2, the
augmenting phase, following the same steps as in Section~\ref{sec:
  adaptive partitioning}.  For each client $j$ and each demand $\nu\in
j$ with total connection value $\barx_{\mu\nu}$ for
$\mu\in\wbarN(\nu)$ less than $1$, we use our $\AugmentToUnit()$
procedure to add additional facilities (possibly split, if necessary)
from $\wtildeN(j)$ to $\wbarN(\nu)$ to make the total connection value
of $\wbarN(\nu)$ equal $1$.

This completes the description of the partitioning
algorithm. Summarizing, for each client $j\in\clientset$ we have
created $r_j$ demands on the same point as $j$ and we created a number
of facilities at each site $i\in\sitesset$. Thus computed sets of
demands and facilities are denoted $\demandset$ and $\facilityset$,
respectively.  For each facility $\mu\in i$ we defined its fractional
opening value $\bary_\mu$, $0\le \bary_\mu\le 1$, and for each demand
$\nu\in j$ we defined its fractional connection value
$\barx_{\mu\nu}\in \braced{0,\bary_\mu}$.  The connections with
$\barx_{\mu\nu} > 0$ define the neighborhood $\wbarN(\nu)$. The subset
of $\wbarN(\nu)$ that are closest to $\nu$ with total connection value
$1/\gamma$ form $\wbarclsnb(\nu)$ and the rest form
$\wbarfarnb(\nu)$. We might split one facility to make the nearest
facilities having total connection value exactly $1/\gamma$.  It
remains to show that this partitioning satisfies all the desired
properties.

%%%%%%%

\medskip
\paragraph{Correctness of partitioning.}
We now argue that our partitioned fractional solution $(\barbfx,\barbfy)$
satisfies all the stated properties. Properties~(PS), (CO) and (NB) are
directly enforced by the algorithm.

(PD'.\ref{PD1:disjoint}) holds because for each primary demand
$\kappa\in p$, $\wbarclsnb(\kappa)$ is the same set as
$\wtildeclsnb(p)$ at the time when $\kappa$ was created, and
$\wtildeclsnb(p)$ is removed from $\wtildeN(p)$ right after this
step. Further, the partitioning algorithm makes $\kappa$ a primary
demand only if $\wtildeclsnb(p)$ is disjoint from the set
$\wbarN(\kappa')$ of all existing primary demands $\kappa'$ at that
iteration, but these neighborhoods are the same as the final close
neighborhoods $\wbarclsnb(\kappa')$.

The justification of (PD'.\ref{PD1:yi}) is similar to that for
(PD.\ref{PD:yi}) from Section~\ref{sec: adaptive partitioning}. All
close neighborhoods of primary demands are disjoint, due to
(PD'.\ref{PD1:disjoint}), so each facility $\mu \in i$ can appear in
at most one $\wbarclsnb(\kappa)$, for some $\kappa\in P$. Condition
(CO) implies that $\bary_{\mu} = \barx_{\mu\kappa}$ as we are only
interested in $\barx_{\mu\kappa} > 0$. As a result, the summation on
the left-hand side is not larger than $\sum_{\mu\in i}\bary_{\mu} =
y_i^\ast$.

Regarding (PD'.\ref{PD1:assign:overlap}), at first glance this
property seems to follow directly from the algorithm, as we only
assign a demand $\nu$ to a primary demand $\kappa$ when $\wbarN(\nu)$
at that iteration overlaps with $\wbarN(\kappa)$ (which is equal to
the final value of $\wbarclsnb(\kappa)$).  However, it is a little
more subtle, as the final $\wbarclsnb(\nu)$ may contain facilities
added to $\wbarN(\nu)$ in Phase 2. Those facilities may turn out to be
closer to $\nu$ than some facilities in $\wbarN(\kappa) \cap
\wtildeN(j) $ (not $\wtildeN_{\cls}(j)$) that we added to
$\wbarN(\nu)$ in Phase 1. If the final $\wbarclsnb(\nu)$ consists only
facilities added in Phase 2, we no longer have the desired overlap of
$\wbarclsnb(\kappa)$ and $\wbarclsnb(\nu)$. Luckily this bad scenario
never occurs. We postpone the proof of this property to
Lemma~\ref{lem: PD1: primary overlap}.  The proof of
(PD'.\ref{PD1:assign:cost}) is similar to that of Lemma~\ref{lem:
  PD:assign:cost holds}, and we defer it to Lemma~\ref{lem: PD1:
  primary optimal}.

(SI'.\ref{SI1:siblings disjoint}) follows directly from the algorithm
because for each demand $\nu\in j$, all facilities added to
$\wbarN(\nu)$ are immediately removed from $\wtildeN(j)$.

The proof of (SI'.\ref{SI1:primary disjoint}) is similar to that of
Lemma~\ref{lem: property SI:primary disjoint holds}. If $\kappa=\nu$
then (SI'.\ref{SI1:primary disjoint}) follows from
(SI'.\ref{SI1:siblings disjoint}), so we can assume that
$\kappa\neq\nu$.  Suppose that $\nu'\in j$ is assigned to $\kappa'\in
P$ and consider the situation after Phase~1. By the way we reassign
facilities in Case~1, at this time we have $\wbarN(\nu)\subseteq
\wbarN(\kappa) = \wbarclsnb(\kappa)$ and $\wbarN(\nu')\subseteq
\wbarN(\kappa') =\wbarclsnb(\kappa')$, so $\wbarN(\nu')\cap
\wbarclsnb(\kappa) = \emptyset$, by (PD'.\ref{PD1:disjoint}).
Moreover, we have $\wtildeN(j) \cap \wbarclsnb(\kappa) = \emptyset$
after this iteration, because any facility that were also in
$\wbarclsnb(\kappa)$ were removed from $\wtildeN(j)$ when $\nu$ was
created. In Phase~2, augmentation does not change $\wbarclsnb(\kappa)$
and all facilities added to $\wbarN(\nu')$ are from the set
$\wtildeN(j)$ at the end of Phase 1, which is a subset of the set
$\wtildeN(j)$ after this iteration, since $\wtildeN(j)$ is
shrinking. So the condition (SI'.\ref{SI1:primary disjoint}) will
remain true.

%%%%%%%%%%%%%%%

\begin{lemma} \label{lem: PD1: primary overlap}
  Property (PD'.\ref{PD1:assign:overlap}) holds.
\end{lemma}

\begin{proof}
Let $j$ be the client for which $\nu\in j$. We consider an iteration when we create $\nu$
from $j$ and assign it to $\kappa$, and throughout the proof notation $\wtildeclsnb(j)$ 
will refer to the value of this set at this particular time.
At this time, $\wbarN(\nu)$ is initialized to $\wtildeclsnb(j)\cap \wbarN(\kappa)$.
Recall that
$\wbarN(\kappa)$ is now equal to $\wbarclsnb(\kappa)$ and this latter set will remain unchanged,
so throughout the proof we will refer to the value of $\wbarclsnb(\kappa)$ at this iteration
as $\wbarclsnb(\kappa)$.
We would like to show that the set $\wtildeclsnb(j)\cap \wbarclsnb(\kappa)$ (which is
not empty) will
be included in $\wbarclsnb(\nu)$ at the end. Technically speaking, this will not be
true due to facility splitting, so we need to rephrase this claim and the proof
in terms of the set of facilities obtained after the algorithm completes.

%%\begin{figure}[ht]
%%\begin{center}
%%\includegraphics[width=3.2in]{./FIGURES/proof_of_lemma_PD'3a.pdf}
%%\caption{Illustration of the sets $\wbarN(\nu)$, $A$, $B$, $E^-$ and $E^+$ in the proof
%%of Lemma~\ref{lem: PD1: primary overlap}.}
%%\label{fig: sets lemma PD'3a}
%%\end{center}
%%\end{figure}

We define the sets $A$, $B$, $E^-$ and $E^+$ as the subsets of $\facilityset$ (the final set
of facilities) that either belonged to or were obtained from splitting facilities in
the sets $\wtildeN(j)$, $\wtildeclsnb(j)\cap \wbarclsnb(\kappa)$, 
$\wtildeclsnb(j) - \wbarclsnb(\kappa)$
and $\wtildeN(j) - \wtildeclsnb(j)$, respectively.
(See Figure~\ref{fig: sets lemma PD'3a}.)
We claim that at the end $B\subseteq \wbarclsnb(\nu)$, with the caveat that the
ties in the definition of $\wbarclsnb(\nu)$ are broken in favor of the facilities in $B$.
(This is the tie-breaking rule that we mentioned in the definition of $\wbarclsnb(\nu)$.)
This will be sufficient to prove the lemma because $B\neq\emptyset$, by the algorithm.

We now prove this claim. Note first that 
$B\subseteq \wbarN(\nu) \subseteq A$, because we never remove facilities from
$\wbarN(\nu)$ and we only add facilities from $\wtildeN(j)$.
Also, $B\cup E^-$ represents the facilities obtained from $\wtildeclsnb(\nu)$, so
 $\sum_{\mu\in B\cup E^-} \bary_{\mu} = 1/\gamma$. 
This and
$B\subseteq \wbarN(\nu)$ implies that the total connection value of
$B\cup (\wbarN(\nu)\cap E^-)$ to $\nu$ is at most $1/\gamma$. But
all facilities in $B\cup (\wbarN(\nu)\cap E^-)$ are closer to $\nu$ than
those in $E^+\cap \wbarN(\nu)$. It follows that
$B\subseteq \wbarclsnb(\nu)$, completing the proof.
\end{proof}

%%%%%%%%%%%%%%

\begin{lemma}\label{lem: PD1: primary optimal}
  Property (PD'.\ref{PD:assign:cost}) holds.
\end{lemma}

\begin{proof}
This proof is similar to that for Lemma~\ref{lem: PD:assign:cost holds}.
For a client $j$ and demand $\eta$, we will write
$\tcccls^\eta(j)$ and $\dmaxcls^\eta(j)$ to denote the values of
$\tcccls(j)$ and $\dmaxcls(j)$ at the time when $\eta$
was created. (Here $\eta$ may or may not be a demand of client $j$).

Suppose $\nu \in j$ is assigned to a primary demand $\kappa \in p$.
By the way primary demands are constructed in the partitioning
algorithm, $\wtildeclsnb(p)$ becomes $\wbarclsnb(\kappa)$, so we have
$\clsdist(\kappa) = \tcccls^\kappa (p)$ and $\clsmax(\kappa) =
\tcccls^\kappa(p)$. Further, since we choose $p$ to minimize
$\tcccls(p) + \dmaxcls(p)$, we thus have that $\tcccls^\kappa(p) +
\dmaxcls^\kappa(p) \leq \tcccls^\kappa(j) + \dmaxcls^\kappa(j)$ at the
time when demand $\kappa$ was created.

Using an argument analogous to that in the proof of Lemma~\ref{lem: tcc optimal}, 
our modified partitioning algorithm guarantees that
  $\tcccls^{\kappa}(j) \leq \tcccls^{\nu}(j)$ and
  $\dmaxcls^{\kappa}(j) \leq \dmaxcls^{\nu}(j)$ since $\nu$ was
  created later.
  Therefore, we have
%
  \begin{align*}
    \clsdist(\kappa) + \clsmax(\kappa) &= \tcccls^{\kappa}(p) +	\dmaxcls^{\kappa}(p) 
					\\
					&\leq \tcccls^{\kappa}(j) + \dmaxcls^{\kappa}(j) 
					\leq \tcccls^{\nu}(j) + \dmaxcls^{\nu}(j) 
					= \clsdist(\nu) + \clsmax(\nu),
  \end{align*}
%
completing the proof.
\end{proof}

%%%%%%%%

Now we have completed the proof that the computed partitioning satisfies
all the required properties. 


\paragraph{Algorithm~{\EBGS}.}
The complete algorithm starts with solving the linear program and
computing the partitioning described earlier in this section.
Given the partitioned fractional solution $(\barbfx,
\barbfy)$ with the desired properties, we start the process of opening
facilities and making connections to obtain an integral
solution. To this end, for each primary demand $\kappa\in P$,
we open exactly one facility $\phi(\kappa)$ in $\wbarclsnb(\kappa)$,
where each $\mu\in\wbarclsnb(\kappa)$ is chosen as $\phi(\kappa)$ with probability
$\gamma\bary_{\mu}$. For all facilities
 $\mu\in\facilityset - \bigcup_{\kappa\in P}\wbarclsnb(\kappa)$,
we open them independently, each with
probability $\gamma\bary_{\mu}$. 

Next, we connect demands to facilities.
Each primary demand $\kappa\in P$ will connect
to the only open facility $\phi(\kappa)$ in $\wbarclsnb(\kappa)$.  
For each non-primary demand $\nu\in \demandset - P$, if
there is an open facility in $\wbarN(\nu)$ then we connect
$\nu$ to the nearest such facility. Otherwise, we connect
$\nu$ to its \emph{target facility} $\phi(\kappa)$, where $\kappa$ is the primary
demand that $\nu$ is assigned to. 

%%%%%%%%%%%

\paragraph{Analysis.}
By the algorithm, for each client $j$, all its $r_j$ demands are connected to
open facilities. If two different siblings $\nu,\nu'\in j$ are assigned, respectively,
to primary demands $\kappa$, $\kappa'$ then, by
Properties~(SI'.\ref{SI1:siblings disjoint}), (SI'.\ref{SI1:primary
  disjoint}), and (PD'.\ref{PD1:disjoint}) we have
%
\begin{equation*}
( \wbarN(\nu) \cup \wbarclsnb(\kappa)) \cap (\wbarN(\nu')\cup \wbarclsnb(\kappa')) = \emptyset.
\end{equation*}
%
This condition guarantees that $\nu$ and $\nu'$ are assigned to different facilities,
regardless whether they are connected to a neighbor facility or to its target facility.
Therefore the computed solution is feasible.

\smallskip

We now estimate the cost of the solution computed by Algorithm {\EBGS}. The lemma
below bounds the expected facility cost.

\begin{lemma} \label{lem: EBGS facility cost}
The expected facility cost $F_{\smallEBGS}$ of Algorithm~{\EBGS} is at most $\gamma F^\ast$.
\end{lemma}

\begin{proof}
By the algorithm, each facility $\mu\in \facilityset$ is opened with
probability $\gamma \bary_{\mu}$, independently of whether it belongs to the
close neighborhood of a primary demand or not. Therefore, by
  linearity of expectation, we have that the expected facility cost is
%
\begin{equation*}
	F_{\smallEBGS} = \sum_{\mu \in \facilityset} f_\mu \gamma \bary_{\mu} 
			= \gamma \sum_{i\in \sitesset} f_i \sum_{\mu\in i} \bary_{\mu} 
			= \gamma \sum_{i \in \sitesset} f_i y_i^\ast = \gamma F^\ast,
\end{equation*}
%
where the second equality follows from (PS.\ref{PS:yi}).
\end{proof}

%%%%%%%%%%%

To bound the connection cost, we start with a lemma
that estimates the cost of indirect connections, between a non-primary demand and its
target facility. The proof of this lemma relies on
Properties~(PD'.\ref{PD1:assign:overlap}) and (PD'.\ref{PD1:assign:cost}) of 
modified partitioning and follows the reasoning in the proof of a similar 
lemma in~\cite{ByrkaGS10,ByrkaA10}.
For the sake of completeness, the complete proof is included in the appendix.

\begin{lemma}\label{lem: EBGS target connection cost}
  In Algorithm~{\EBGS}, let $\gamma$ be a constant such that $1 <
  \gamma < 2$, for a non-primary demand $\nu$, in the event that no
  facility in $\wbarN(\nu)$ opens, the expected connection cost is no
  more than $\clsdist(\nu)+\clsmax(\nu)+\fardist(\nu)$.
\end{lemma}

We are now ready to bound the overall connection cost of Algorithm~{\EBGS}.

\begin{lemma}\label{lem: EBGS connection cost}
  Assuming that $1 < \gamma < 2$, the expected connection
  cost $C_{\smallEBGS}$ of Algorithm~{\EBGS} is at most
  $C^\ast\cdot\max\{\frac{1/e+1/e^\gamma}{1-1/\gamma},
  1+\frac{2}{e^\gamma}\}$.
\end{lemma}

\begin{proof}
  The argument is similar to that in~\cite{ByrkaGS10}. Fix some
  non-primary demand $\nu$. We estimate its connection cost by a
  provably worse random process like we did in Algorithm {\ECHS}. Let
  $\wbarclsnb(\nu) = \{\mu_1,\ldots,\mu_l\}$ and $\wbarfarnb(\nu) =
  \{\mu_{l+1}, \ldots, \mu_{l'}\}$, where facilities are ordered by
  non-decreasing distance to $\nu$, and
  $d_1,\ldots,d_l,d_{l+1},\ldots,d_{l'}$ be the corresponding distance
  to $\nu$. Let $\Lambda_{\nu}$ be the event that none of
  $\wbarN(\nu)$ opens in algorithm {\EBGS}'s integral solution and
  $\kappa$ be the primary demand that $\nu$ was assigned to, we then
  have $\Exp[d_{\phi(\kappa)\nu}\mid \Lambda_{\nu}] \leq \clsdist(\nu)
  + \clsmax(\nu) + \fardist(\nu)$ by Lemma~\ref{lem: EBGS target
    connection cost}.

  Let $C_{\nu}$ be the random variable of the distance from $\nu$ to
  the facility that it connects to in the integral solution. A similar
  argument as in the connection cost analysis of algorithm {\ECHS}
  will then show that the expected distance $\Exp[C_\nu]$ is no more
  than
  \begin{align*}
    \Exp[C_{\nu}] 
    &\leq \left(1-\prod_{s=1}^l (1-\gamma\bary_s)\right) \sum_{s=1}^l d_s \gamma\bary_s\\
    &+ \left(\prod_{s=1}^l(1-\gamma\bary_s) - \prod_{s=1}^{l'}(1-\gamma\bary_s)\right) \left(\sum_{s=l+1}^{l'} d_s\bary_s\;/ \;\sum_{s=l+1}^{l'} \bary_s \right)\\
    &+ \left(\prod_{s=1}^{l'} (1-\gamma\bary_s)\right) \Exp[d_{\phi(\kappa)\nu} \mid \Lambda_\nu]\\
    &\leq (1-1/e)\clsdist(\nu) + (1/e - 1/e^\gamma)\fardist(\nu) + 1/e^\gamma (\clsdist(\nu) + \clsmax(\nu) + \fardist(\nu))\\
\\
  &\leq 
	\textstyle
	\clsdist(\nu)(1-\frac{1}{e}) + \fardist(\nu)(\frac{1}{e}-\frac{1}{e^\gamma})
	 			+ (\clsdist(\nu)+2\fardist(\nu))\frac{1}{e^\gamma}
\\
  &\leq
	\textstyle
  \concost(\nu)((1-\rho_{\nu})(\frac{1/e+1/e^\gamma}{1-1/\gamma})
  + \rho_{\nu}(1+\frac{2}{e^\gamma}) 
\\
  &\leq 
	\textstyle
	\concost(\nu) \cdot \max\Big\{\frac{1/e+1/e^\gamma}{1-1/\gamma},
  								1+\frac{2}{e^\gamma}\Big\},
\end{align*}
%
where $\rho_{\nu}=\clsdist(\nu)/\concost(\nu)$. It is easy to see that
$\rho_{\nu}$ is between 0 and 1. Since $\sum_{\nu\in j} C^{\avg}(\nu)
= \sum_{\nu\in j}\sum_{\mu\in\facilityset} d_{\mu\nu}\barx_{\mu\nu} =
\sum_{i\in\sitesset} d_{ij}x_{ij}^\ast = C_j^\ast$, summing over all
clients $j$ we have total connection cost bounded by $C^\ast
\max\{\frac{1/e+1/e^\gamma}{1-1/\gamma}, 1+\frac{2}{e^\gamma}\}$.
\end{proof}

Recall that the expected facility cost is bounded by $\gamma F^\ast$,
as argued earlier. Hence the total cost is bounded by $\max\{\gamma,
\frac{1/e+1/e^\gamma}{1-1/\gamma}, 1+\frac{2}{e^\gamma}\}\cdot
\LP^\ast$. Picking $\gamma=1.575$ we obtain the desired ratio.


\begin{theorem}\label{thm:ebgs}
  Algorithm~{\EBGS} is a $1.575$-approximation algorithm for \FTFP.
\end{theorem}



