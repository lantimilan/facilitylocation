\section{Adaptive Partitioning}
\label{sec: adaptive partitioning}

In this section we develop our second technique, which we
call \emph{adaptive partitioning}. Given an FTFP instance
and an optimal fractional solution $(\bfx^\ast, \bfy^\ast)$
to LP~(\ref{eqn:fac_primal}), we split each client $j$ into
$r_j$ individual \emph{unit demand points} (or just
\emph{demands}), and we split each site $i$ into no more
than $|\sitesset|+2R|\clientset|^2$ \emph{facility points} (or
\emph{facilities}), where $R=\max_{j\in\clientset}r_j$. We
denote the demand set by $\demandset$ and the facility set
by $\facilityset$, respectively.  We will also partition
$(\bfx^\ast,\bfy^\ast)$ into a fractional solution
$(\barbfx,\barbfy)$ for the split instance.  We will
typically use symbols $\nu$ and $\mu$ to index demands and
facilities respectively, that is $\barbfx =
(\barx_{\mu\nu})$ and $\barbfy = (\bary_{\mu})$.  As before,
the \emph{neighborhood of a demand} $\nu$ is
$\wbarN(\nu)=\braced{\mu\in\facilityset \suchthat
  \barx_{\mu\nu}>0}$.  We will use notation $\nu\in j$ to
mean that $\nu$ is a demand of client $j$; similarly,
$\mu\in i$ means that facility $\mu$ is on site
$i$. Different demands of the same client (that is,
$\nu,\nu'\in j$) are called \emph{siblings}.  Further, we
use the convention that $f_\mu = f_i$ for $\mu\in i$,
$\alpha_\nu^\ast = \alpha_j^\ast$ for $\nu\in j$ and
$d_{\mu\nu} = d_{\mu j} = d_{ij}$ for $\mu\in i$ and $\nu\in
j$.  We define $\concost_{\nu}
=\sum_{\mu\in\wbarN(\nu)}d_{\mu\nu}\barx_{\mu\nu} =
\sum_{\mu\in\facilityset}d_{\mu\nu}\barx_{\mu\nu}$. 
One can think of $\concost_{\nu}$ as the
average connection cost of demand $\nu$, if we chose a
connection to facility $\mu$ with probability
$\barx_{\mu\nu}$. In our partitioned fractional solution we
guarantee for every $\nu$ that $\sum_{\mu\in\facilityset}
\barx_{\mu\nu}=1$.

Some demands in $\demandset$ will be designated as
\emph{primary demands} and the set of primary demands will
be denoted by $P$. In addition, we will use the overlap
structure between demand neighborhoods to define a mapping
that assigns each demand $\nu\in\demandset$ to some primary
demand $\kappa\in P$. As shown in the rounding algorithms in
later sections, for each primary demand we guarantee exactly
one open facility in its neighborhood, while for a
non-primary demand, there is constant probability that none
of its neighbors open. In this case we estimate its
connection cost by the distance to the facility opened in
its assigned primary demand's neighborhood. For this reason
the connection cost of a primary demand must be ``small''
compared to the non-primary demands assigned to it. We also
need sibling demands assigned to different primary demands to satisfy
the fault-tolerance requirement. Specifically, this
partitioning will be constructed to satisfy a number of
properties that are detailed below.
%
\begin{description}
	
      \renewcommand{\theenumii}{(\alph{enumii})}
      \renewcommand{\labelenumii}{\theenumii}

\item{(PS)} \emph{Partitioned solution}.
Vector $(\barbfx,\barbfy)$ is a partition of $(\bfx^\ast,\bfy^\ast)$, with unit-value
  demands, that is:

	\begin{enumerate}
		%
	\item \label{PS:one} 
          $\sum_{\mu\in\facilityset} \barx_{\mu\nu} = 1$ for each demand $\nu\in\demandset$. 
		%
	\item \label{PS:xij} $\sum_{\mu\in i, \nu\in j} \barx_{\mu\nu}
          = x^\ast_{ij}$ for each site $i\in\sitesset$ and client $j\in\clientset$.
		%
	\item \label{PS:yi}
          $\sum_{\mu\in i} \bary_{\mu} = y^\ast_i$ for each site $i\in\sitesset$.
		%
	\end{enumerate}
		
\item{(CO)} \emph{Completeness.}
	Solution   $(\barbfx,\barbfy)$ is complete, that is $\barx_{\mu\nu}\neq 0$ implies
				$\barx_{\mu\nu} = \bary_{\mu}$, for all $\mu\in\facilityset, \nu\in\demandset$.

\item{(PD)} \emph{Primary demands.}
	Primary demands satisfy the following conditions:

	\begin{enumerate}
		
	\item\label{PD:disjoint}  For any two different primary demands $\kappa,\kappa'\in P$ we have
				$\wbarN(\kappa)\cap \wbarN(\kappa') = \emptyset$.

	\item \label{PD:yi} For each site $i\in\sitesset$, 
		$ \sum_{\mu\in i}\sum_{\kappa\in P}\barx_{\mu\kappa} \leq y_i^\ast$.
		
	\item \label{PD:assign} Each demand $\nu\in\demandset$ is assigned
        to one primary demand $\kappa\in P$ such that

  			\begin{enumerate}
	
				\item \label{PD:assign:overlap} $\wbarN(\nu) \cap \wbarN(\kappa) \neq \emptyset$, and
				%
				\item \label{PD:assign:cost} $\concost_{\nu}+\alpha_{\nu}^\ast \geq
        			\concost_{\kappa}+\alpha_{\kappa}^\ast$.

			\end{enumerate}

	\end{enumerate}
	
\item{(SI)} \emph{Siblings}. For any pair $\nu,\nu'$ of different siblings we have
  \begin{enumerate}

	\item \label{SI:siblings disjoint}
		  $\wbarN(\nu)\cap \wbarN(\nu') = \emptyset$.
		
	\item \label{SI:primary disjoint} If $\nu$ is assigned to a primary demand $\kappa$ then
 		$\wbarN(\nu')\cap \wbarN(\kappa) = \emptyset$. In particular, by Property~PD(\ref{PD:assign:overlap}),
		this implies that different sibling demands are assigned to different primary demands.

	\end{enumerate}
	
\end{description}

As we shall demonstrate in later sections, these properties allow us
to extend known UFL rounding algorithms to obtain an integral solution
to our FTFP problem with a matching approximation ratio. Our
partitioning is ``adaptive" in the sense that it is constructed one
demand at a time, and the connection values for the demands of a
client depend on the choice of earlier demands, of this or other
clients, and their connection values. We would like to point out that
the adaptive partitioning process for the $1.575$-approximation
algorithm (Section~\ref{sec: 1.575-approximation}) is more subtle than
the $3$-apprximation (Section~\ref{sec: 3-approximation}) and the
$1.736$-approximation algorithms (Section~\ref{sec:
  1.736-approximation}), due to the introduction of close and far
neighborhood.

%%%%%%%%%%%%%%%%

\paragraph{Implementation of Adaptive Partitioning.}
We now describe an algorithm for partitioning the instance
and the fractional solution so that the properties (PS),
(CO), (PD), and (SI) are satisfied.  Recall that
$\facilityset$ and $\demandset$, respectively, denote the
sets of facilities and demands that will be created in this
stage, and $(\barbfx,\barbfy)$ is the partitioned solution
to be computed. 

The adaptive partitioning algorithm consists of two phases:
Phase 1 is called the partition phase and Phase 2 is called
the augmenting phase. Phase 1 is done in iterations, where
in each iteration we find the ``best'' client $j$ and create a
new demand $\nu$ out of it. This demand either becomes a
primary demand itself, or it is assigned to some existing
primary demand. We call a client $j$ \emph{exhausted} when
all its $r_j$ demands have been created and assigned to some
primary demands. Phase 1 completes when all clients are
exhausted. In Phase 2 we ensure that every demand has a
total connection values equal to $1$, that is condition (PS.\ref{PS:one}).

For each site $i$ we will initially create one ``big" facility $\mu$
with initial value $\bary_\mu = y^\ast_i$.  While we partition the
instance, creating new demands and connections, this facility may end
up being split into more facilities to preserve completeness of the
fractional solution. Also, we will gradually decrease the fractional
connection vector for each client $j$, to account for the demands
already created for $j$ and their connection values.  These decreased
connection values will be stored in an auxiliary vector
$\tildebfx$. The intuition is that $\tildebfx$ represents the part of
$\bfx^\ast$ that still has not been allocated to existing demands and
future demands can use $\tildebfx$ for their connections. For
technical reasons, $\tildebfx$ will be indexed by facilities (rather
than sites) and clients, that is $\tildebfx = (\tildex_{\mu j})$.  At
the beginning, we set $\tildex_{\mu j}\assign x_{ij}^\ast$ for each
$j\in\clientset$, where $\mu\in i$ is the single facility created
initially at site $i$.  At each step, whenever we create a new demand
$\nu$ for a client $j$, we will define its values $\barx_{\mu\nu}$ and
appropriately reduce the values $\tildex_{\mu j}$, for all facilities
$\mu$. We will deal with two types of neighborhoods, with respect to
$\tildebfx$ and $\barbfx$, that is $\wtildeN(j)=\{\mu\in\facilityset
\suchthat\tildex_{\mu j} > 0\}$ for $j\in\clientset$ and
$\wbarN(\nu)=\{\mu\in\facilityset \suchthat \barx_{\mu\nu} >0\}$ for
$\nu\in\demandset$.  During this process we preserve the completeness
(CO) of the fractional solutions $\tildebfx$ and $\barbfx$. More
precisely, the following properties will hold for every facility $\mu$
after every iteration:
%
\begin{description}
	
	\item{(c1)} For each demand $\nu$ either $\barx_{\mu\nu}=0$ or
			$\barx_{\mu\nu}=\bary_{\mu}$. This is the same
      condition as condition (CO), yet we repeat it here as
      (c1) needs to hold after every iteration, while
      condition (CO) only applies to the final partitioned
      fractional solution $(\barbfx, \barbfy)$.

	\item{(c2)} For each client $j$,
			either $\tildex_{\mu j}=0$ or $\tildex_{\mu j}=\bary_{\mu}$.
			
\end{description}

A full description of the algorithm is given in
Pseudocode~\ref{alg:lpr2}.  Initially, the set $U$ of
non-exhausted clients contains all clients, the set
$\demandset$ of demands is empty, the set $\facilityset$ of
facilities consists of one facility $\mu$ on each site $i$
with $\bary_\mu = y^\ast_i$, and the set $P$ of primary
demands is empty (Lines 1--4).  In one iteration of the
while loop (Lines 5--8), for each client $j$ we
compute a quantity called $\tcc(j)$ (tentative connection
cost), that represents the average distance from $j$ to the
set $\wtildeN_1(j)$ of the nearest facilities $\mu$ whose
total connection value to $j$ (the sum of $\tildex_{\mu
  j}$'s) equals $1$.  This set is computed by Procedure
$\NearestUnitChunk()$ (see Pseudocode~\ref{alg:helper},
Lines~1--9), which adds facilities to $\wtildeN_1(j)$ in
order of nondecreasing distance, until the total connection
value is exactly $1$. (The procedure actually uses the
$\bary_\mu$ values, which are equal to the connection values,
by the completeness condition (c2).)  This may require splitting the last added
facility and adjusting the connection values so that
conditions (c1) and (c2) are preserved.

%%%%%%%%%%%

\begin{algorithm}[ht]
  \caption{Algorithm: Adaptive Partitioning}
  \label{alg:lpr2}
  \begin{algorithmic}[1]
    \Require $\sitesset$, $\clientset$, $(\bfx^\ast,\bfy^\ast)$
    \Ensure  $\facilityset$,  $\demandset$, $(\barbfx, \barbfy)$ 
    \Comment Unspecified $\barx_{\mu \nu}$'s and $\tildex_{\mu j}$'s are assumed to be $0$

    \State $\tildebfr \assign \bfr, U\assign \clientset, \facilityset\assign \emptyset,
    \demandset\assign \emptyset, P\assign \emptyset$
    \Comment{Phase 1}

    \For{each site $i\in\sitesset$} 
    \State create a facility $\mu$ at $i$ and add $\mu$ to $\facilityset$
    \State $\bary_\mu \assign y_i^\ast$ and $\tildex_{\mu j}\assign
    x_{ij}^\ast$ for each $j\in\clientset$ 
    \EndFor

    \While{$U\neq \emptyset$}
    \For{each $j\in U$}
    \State $\wtildeN_1(j) \assign {\NearestUnitChunk}(j, \facilityset, \tildebfx, \barbfx, \barbfy)$ \Comment see Pseudocode~\ref{alg:helper}
    \State $\tcc(j)\assign \sum_{\mu\in \wtildeN_1(j)} d_{{\mu}j}\cdot \tildex_{\mu j}$
    \EndFor
 
    \State $p \assign {\argmin}_{j\in U}\{ \tcc(j)+\alpha_j^\ast \}$
    \State create a new demand $\nu$ for client $p$

    \If{$\wtildeN_1 (p)\cap \wbarN(\kappa) \neq \emptyset$
      for some primary demand $\kappa\in P$}
    \State assign $\nu$ to $\kappa$
    \State $\barx_{\mu \nu}\assign \tildex_{\mu p}$ and $\tildex_{\mu p}\assign 0$ for each $\mu \in \wtildeN(p) \cap \wbarN(\kappa)$
    \Else 
    \State make $\nu$ primary, $P \assign P \cup \{\nu\}$, assign $\nu$ to itself
    \State set $\barx_{\mu\nu} \assign \tildex_{\mu p}$ and $\tildex_{\mu p}\assign 0$ for each $\mu\in \wtildeN_1(p)$

    \EndIf
    \State $\demandset\assign \demandset\cup \{\nu\},
    \tilder_p \assign \tilder_p -1$
	\State \textbf{if} {$\tilder_p=0$} \textbf{then} $U\assign U \setminus \{p\}$
    \EndWhile

    \For{each client $j\in\clientset$} \Comment{Phase 2}
    \For{each demand $\nu\in j$}    \Comment{each client $j$ has $r_j$ demands}
    \State \textbf{if} $\sum_{\mu\in \wbarN(\nu)}\barx_{\mu\nu}<1$
    \textbf{then} $\AugmentToUnit(\nu, j, \facilityset, \tildebfx, \barbfx, \barbfy)$ \Comment see Pseudocode~\ref{alg:helper}
    \EndFor
    \EndFor
  \end{algorithmic}
\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% subroutine: NearestUnitChunk and AugmentToUnit
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{algorithm}[ht]
  \caption{Helper functions used in Pseudocode~\ref{alg:lpr2}}
  \label{alg:helper}
  \begin{algorithmic}[1]
    \Function{\NearestUnitChunk}{$j, \facilityset, \tildebfx, \barbfx,\barbfy$}		
						\Comment upon return, $\sum_{\mu\in\wtildeN_1(j)} \tildex_{\mu j} = 1$
    \State Let $\wtildeN(j) = \{\mu_1,...,\mu_{q}\}$ where $d_{\mu_1 j} \leq d_{\mu_2 j} \leq \ldots \leq d_{\mu_{q j}}$
    \State Let $l$ be such that $\sum_{k=1}^{l} \bary_{\mu_k} \geq 1$ and $\sum_{k=1}^{l -1} \bary_{\mu_{k}} < 1$
    \State Create a new facility $\sigma$ at the same site as $\mu_l$ and add it to $\facilityset$
			\Comment split $\mu_l$
    \State Set $\bary_{\sigma}\assign \sum_{k=1}^{l} \bary_{\mu_{k}}-1$
					and $\bary_{\mu_l} \assign \bary_{\mu_l} - \bary_{\sigma}$
    \State For each $\nu\in\demandset$ with $\barx_{\mu_{l}\nu}>0$
 			set $\barx_{\mu_{l}\nu} \assign \bary_{\mu_l}$ and $\barx_{\sigma \nu} \assign \bary_{\sigma}$
    \State For each $j'\in\clientset$ with $\tildex_{\mu_{l} j'}>0$ (including $j$)
			set $\tildex_{\mu_l j'} \assign \bary_{\mu_l}$ and $\tildex_{\sigma j'} \assign \bary_\sigma$
	\State (All other new connection values are set to $0$)
    \State \Return $\wtildeN_1(j) = \{\mu_{1},\ldots,\mu_{l-1}, \mu_{l}\}$    				
    \EndFunction

    \Function{\AugmentToUnit}{$\nu, j, \facilityset, \tildebfx, \barbfx, \barbfy$}
    					\Comment $\nu$ is a demand of client $j$
    \While{$\sum_{\mu\in \facilityset} \barx_{\mu\nu} <1$}
    					\Comment upon return, $\sum_{\mu\in\wbarN(\nu)} \barx_{\mu\nu} = 1$
    \State Let $\eta$ be any facility such that $\tildex_{\eta j} > 0$
    \If{$1-\sum_{\mu\in \facilityset} \barx_{\mu\nu} \geq \tildex_{\eta j}$}
    \State $\barx_{\eta\nu} \assign \tildex_{\eta j}, \tildex_{\eta j} \assign 0$
    \Else
    \State Create a new facility $\sigma$ at the same site as $\eta$ and add it to $\facilityset$
    					\Comment split $\eta$
    \State Let $\bary_\sigma \assign 1-\sum_{\mu\in \facilityset} \barx_{\mu\nu}, \bary_{\eta} \assign \bary_{\eta} - \bary_{\sigma}$
    \State Set $\barx_{\sigma\nu}\assign \bary_{\sigma},\; \barx_{\eta \nu} \assign  0,\; \tildex_{\eta j} \assign \bary_{\eta}, \; \tildex_{\sigma j} \assign 0$
    \State For each $\nu' \neq \nu$ with $\barx_{\eta \nu'}>0$ set $\barx_{\eta \nu'} \assign \bary_{\eta},\; \barx_{\sigma \nu'} \assign \bary_{\sigma}$
    \State For each $j' \neq j$ with $\tildex_{\eta j'}>0$ set $\tildex_{\eta j'} \assign \bary_{\eta}, \tildex_{\sigma j'} \assign \bary_{\sigma}$
	\State  (All other new connection values are set to $0$)
    \EndIf
    \EndWhile
    \EndFunction
  \end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%


The next step is to pick a client $p$ with minimum
$\tcc(p)+\alpha_p^\ast$ and create a demand $\nu$ for $p$
(Lines~9--10). If $\wtildeN_1(p)$ overlaps the neighborhood
of some existing primary demand $\kappa$ (if there are
multiple such $\kappa$'s, pick any of them), we assign $\nu$
to $\kappa$, and $\nu$ acquires all the connection values
$\tildex_{\mu p}$ between client $p$ and facility $\mu$ in
$\wtildeN(p)\cap \wbarN(\kappa)$ (Lines~11--13). Note that
although we check for overlap with $\wtildeN_1(p)$, we then
move all facilities in the intersection with $\wtildeN(p)$,
a bigger set, into $\wbarN(\nu)$.  The other case is when
$\wtildeN_1(p)$ is disjoint from the neighborhoods of all
existing primary demands. Then, in Lines~15--16, $\nu$
becomes itself a primary demand and we assign $\nu$ to
itself. It also inherits the connection values to all
facilities $\mu\in\wtildeN_1(p)$ from $p$ (recall that
$\tildex_{\mu p} = \bary_{\mu}$), with all other
$\barx_{\mu\nu}$ values set to $0$.

At this point all primary demands satisfy
Property~(PS.\ref{PS:one}), but this may not be true for
non-primary demands. For those demands we still may need to
adjust the $\barx_{\mu\nu}$ values so that the total
connection value for $\nu$, that is $\connsum(\nu) \stackrel{\mathrm{def}}{=}
\sum_{\mu\in\facilityset}\barx_{\mu \nu}$, is equal $1$. This
is accomplished by Procedure $\AugmentToUnit()$ (definition
in Pseudocode~\ref{alg:helper}, Lines~10--21) that allocates
to $\nu\in j$ some of the remaining connection values
$\tildex_{\mu j}$ of client $j$ (Lines 19--21).
$\AugmentToUnit()$ will repeatedly pick any facility $\eta$ with
$\tildex_{\eta j} >0$.  If $\tildex_{\eta j} \leq
1-\connsum(\nu)$, then the connection value $\tildex_{\eta
  j}$ is reassigned to $\nu$. 
Otherwise, $\tildex_{\eta j} >
1-\connsum(\nu)$, in which case we split $\eta$ so that
connecting $\nu$ to one of the created copies of $\eta$ will
make $\connsum(\nu)$ equal $1$, and we'll be done.

\smallskip

Notice that we start with $|\sitesset|$ facilities and in
each iteration of the while loop in Line~5 each client causes at most one split.
 We have a total of no more than $R|\clientset|$ iterations as in
each iteration we create one demand. (Recall that $R =
\max_jr_j$.) In Phase 2 we do an augment step for each
demand $\nu$ and this creates no more than $R|\clientset|$
new facilities.  So the total number of facilities we
created will be at most $|\sitesset|+ R|\clientset|^2 +
R|\clientset| \leq |\sitesset| + 2R|\clientset|^2$, which is
polynomial in $|\sitesset|+|\clientset|$ due to our earlier
bound on $R$.

%%%%%%

\medskip

\emparagraph{Correctness.}  We now show that all the
required properties (PS), (CO), (PD) and (SI) are satisfied
by the above construction.

Properties~(PS) and (CO) follow directly from the
algorithm. (CO) is implied by the completeness condition
(c1) that the algorithm maintains after each
iteration. Condition~(PS.\ref{PS:one}) is a result of
calling Procedure~$\AugmentToUnit()$ in Line~21. To see that
(PS.\ref{PS:xij}) holds, note that
at each step the algorithm maintains the
invariant that, for every $i\in\sitesset$ and
$j\in\clientset$, we have $\sum_{\mu\in i}\sum_{\nu \in j}
\barx_{\mu \nu} + \sum_{\mu\in i} \tildex_{\mu j} =
x_{ij}^\ast$. In the end, we will create $r_j$ demands for
each client $j$, with each demand $\nu\in j$ satisfying
(PS.\ref{PS:one}), and thus $\sum_{\nu\in
  j}\sum_{\mu\in\facilityset}\barx_{\mu\nu}=r_j$.  This
implies that $\tildex_{\mu j}=0$ for every facility
$\mu\in\facilityset$, and PS(\ref{PS:xij}) follows.
PS(\ref{PS:yi}) holds because every time we split a
facility $\mu$ into $\mu'$ and $\mu''$, the sum of
$\bary_{\mu'}$ and $\bary_{\mu''}$ is equal to the old value of
$\bary_{\mu}$.

Now we deal with properties in group (PD).  First,
(PD.\ref{PD:disjoint}) follows directly from the algorithm,
Pseudocode~\ref{alg:lpr2} (Lines 14--16), since every
primary demand has its neighborhood fixed when created, and
that neighborhood is disjoint from those of the existing primary
demands.

Property (PD.\ref{PD:yi}) follows from (PD.\ref{PD:disjoint}), (CO) and
(PS.\ref{PS:yi}). In more detail, it can be justified as
follows. By (PD.\ref{PD:disjoint}), for each $\mu\in i$ there
is at most one $\kappa\in P$ with $\barx_{\mu\kappa} > 0$
and we have $\barx_{\mu\kappa} = \bary_{\mu}$ due do (CO).
Let $K\subseteq i$ be the set of those $\mu$'s for which
such $\kappa\in P$ exists, and denote this $\kappa$ by
$\kappa_\mu$. Then, using conditions (CO) and
(PS.\ref{PS:yi}), we have $ \sum_{\mu\in i}\sum_{\kappa\in
  P}\barx_{\mu\kappa} = \sum_{\mu\in K}\barx_{\mu\kappa_\mu}
= \sum_{\mu\in K}\bary_{\mu} \leq \sum_{\mu\in i}
\bary_{\mu} = y_i^\ast$.

Property (PD.\ref{PD:assign:overlap}) follows from the way the algorithm
assigns primary demands.  When demand $\nu$ of
client $p$ is assigned to a primary demand $\kappa$ in
Lines~11--13 of Pseudocode~\ref{alg:lpr2}, we move all
facilities in $\wtildeN(p)\cap \wbarN(\kappa)$ (the
intersection is nonempty) into $\wbarN(\nu)$, and we never
remove a facility from $\wbarN(\nu)$.  We postpone the proof 
for (PD.\ref{PD:assign:cost}) to Lemma~\ref{lem: PD:assign:cost holds}.

Finally we argue that the properties in group (SI)
hold. (SI.\ref{SI:siblings disjoint}) is easy, since for any client
$j$, each facility $\mu$ is added to the neighborhood of at most one
demand $\nu\in j$, by setting $\barx_{\mu\nu}$ to $\bary_\mu$, while
other siblings $\nu'$ of $\nu$ have $\barx_{\mu\nu'}=0$. Note that
right after a demand $\nu\in p$ is created, its neighborhood is
disjoint from the neighborhood of $p$, that is $\wbarN(\nu)\cap
\wtildeN(p) = \emptyset$, by Lines~11--13 of the algorithm. Thus all
demands of $p$ created later will have neighborhoods disjoint from the
set $\wbarN(\nu)$ before the augmenting phase 2. Furthermore,
Procedure~$\AugmentToUnit()$ preserves this property, because when it
adds a facility to $\wbarN(\nu)$ then it removes it from
$\wtildeN(p)$, and in case of splitting, one resulting facility is
added to $\wbarN(\nu)$ and the other to $\wtildeN(p)$. Property
(SI.\ref{SI:primary disjoint}) is shown below in Lemma~\ref{lem:
  property SI:primary disjoint holds}.

It remains to show Properties~(PD.\ref{PD:assign:cost}) and
(SI.\ref{SI:primary disjoint}). We show them in the lemmas
below, thus completing the description of our adaptive
partition process.

%%%%%%%

\begin{lemma}\label{lem: property SI:primary disjoint holds}
  Property~(SI.\ref{SI:primary disjoint}) holds after the
  Adaptive Partitioning stage.
\end{lemma}

\begin{proof}
  Let $\nu_1,\ldots,\nu_{r_j}$ be the demands of a client
  $j\in\clientset$, listed in the order of creation, and, for each
  $q=1,2,\ldots,r_j$, denote by $\kappa_q$ the primary demand that
  $\nu_q$ is assigned to. After the completion of Phase~1 of
  Pseudocode~\ref{alg:lpr2} (Lines 5--18), we have
  $\wbarN(\nu_s)\subseteq \wbarN(\kappa_s)$ for  $s=1,\ldots,r_j$. 
Since any two primary demands have disjoint
  neighborhoods, we have $\wbarN(\nu_s) \cap \wbarN(\kappa_q) =
  \emptyset$ for any $s\neq q$, that is
	Property~(SI.\ref{SI:primary disjoint}) holds right after Phase~1.

        After Phase~1 all neighborhoods $\wbarN(\kappa_s),
        s=1,\ldots,r_j$ have already been fixed and they do not change
        in Phase~2.  None of the facilities in $\wtildeN(j)$ appear in
        any of $\wbarN(\kappa_s)$ for $s=1,\ldots,r_j$, by the way we
        allocate facilities in Lines~13 and 16.  Therefore during the
        augmentation process in Phase~2, when we add facilities from
        $\wtildeN(j)$ to $\wbarN(\nu)$, for some $\nu\in j$
        (Line~19--21 of Pseudocode~\ref{alg:lpr2}), all the required
        disjointness conditions will be preserved.
\end{proof}

%%%%%%%

We need one more lemma before proving our last property
(PD.\ref{PD:assign:cost}).  For a client $j$ and a demand
$\nu$, we use notation $\tcc_{\nu}(j)$ for the value of
$\tcc(j)$ at the time when $\nu$ was created. (It is not
necessary that $\nu\in j$ but we assume that $j$ is not
exhausted at that time.)


\begin{lemma}\label{lem: tcc optimal}
  Let $\eta$ and $\nu$ be two demands, with $\eta$ created
  not later than $\nu$, and let $j\in\clientset$ be a client
  that is not exhausted when $\nu$ is created. Then we have
\begin{description}
	\item{(a)} $\tcc_\eta(j) \le \tcc_{\nu}(j)$, and 
	\item{(b)} if $\nu\in j$ then $\tcc_\eta(j) \le \concost_{\nu}$.
\end{description}
\end{lemma}

\begin{proof}
  We focus first on the time when demand $\eta$ is about to be created,
  right after the call to $\NearestUnitChunk()$ in
  Pseudocode~\ref{alg:lpr2}, Line~7.  Let $\wtildeN(j) =
  \{\mu_1,...,\mu_q\}$ with all facilities $\mu_s$ ordered
  according to nondecreasing distance from $j$.  Consider
  the following linear program:
%
\begin{alignat*}{1}
	\textrm{minimize} \quad & \sum_s d_{\mu_s j}z_s
			\\
	\textrm{subject to} \quad & \sum_s z_s  \ge 1
			\\
 	0 &\le z_s \le \tildex_{\mu_s j} \quad \textrm{for all}\ s
\end{alignat*}
%
  This is a fractional
  minimum knapsack covering problem (with knapsack size equal $1$) and its optimal fractional
  solution is the greedy solution, whose value is exactly
  $\tcc_\eta(j)$.  

On the other hand, we claim that
  $\tcc_\nu(j)$ can be thought of as the value of some feasible
  solution to this linear program, and that the same is true for $\concost_{\nu}$ if $\nu\in j$.
  Indeed, each of these
  quantities involves some later values $\tildex_{\mu j}$,
  where $\mu$ could be one of the facilities $\mu_s$ or a
  new facility obtained from splitting. For each $s$,
  however, the sum of all values $\tildex_{\mu j}$,
  over the facilities $\mu$ that were split from $\mu_s$, cannot exceed
 the value $\tildex_{\mu_s j}$ at the time when
  $\eta$ was created, because splitting facilities preserves this sum and
 creating new demands for $j$ can only decrease it.
Therefore both quantities
  $\tcc_\nu(j)$ and $\concost_{\nu}$ (for $\nu\in j$) correspond to some
  choice of the $z_s$ variables (adding up to $1$), and the
  lemma follows.
\end{proof}

%%%%%%%

\begin{lemma}\label{lem: PD:assign:cost holds}
Property~(PD.\ref{PD:assign:cost}) holds after the Adaptive Partitioning stage.
\end{lemma}

\begin{proof}
Suppose that demand $\nu\in j$ is assigned to some primary demand $\kappa\in p$.
Then
%
\begin{eqnarray*}
 \concost_{\kappa} + \alpha_{\kappa}^\ast \;=\; \tcc_\kappa(p) + \alpha^\ast_p
 					\;\le\; \tcc_\kappa(j) + \alpha^\ast_j   
					\;\le\; \concost_{\nu} + \alpha^\ast_\nu.
\end{eqnarray*}
%
We now justify this derivation. By definition we have
$\alpha_{\kappa}^\ast = \alpha^\ast_p$.  Further, by the
algorithm, if $\kappa$ is a primary demand of client $p$,
then $\concost_{\kappa}$ is equal to $\tcc(p)$ computed when
$\kappa$ is created, which is exactly $\tcc_\kappa(p)$. Thus
the first equation is true. The first inequality follows
from the choice of $p$ in Line~9 in
Pseudocode~\ref{alg:lpr2}. The last inequality holds
because $\alpha^\ast_j = \alpha^\ast_\nu$ (due to $\nu\in
j$), and because $\tcc_\kappa(j) \le \concost_{\nu}$, which
follows from Lemma~\ref{lem: tcc optimal}.
\end{proof}

We have thus proved that all properties (PS), (CO), (PD) and (SI) hold
for our partitioned fractional solution $(\barbfx,\barbfy)$. In the
following sections we show how to use these properties to round the
fractional solution to an approximate integral solution. For the
$3$-approximation algorithm (Section~\ref{sec: 3-approximation}) and
the $1.736$-approximation algorithm (Section~\ref{sec:
  1.736-approximation}), the first phase of the algorithm is exactly
the same partition process as described above. However, the
$1.575$-approximation algorithm (Section~\ref{sec:
  1.575-approximation}) demands a more sophisticated partitioning
process as the interplay between close and far neighborhood of sibling
demands result in more delicate properties that our partitioned
fractional solution must satisfy.
