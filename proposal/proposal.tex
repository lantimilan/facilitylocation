\documentclass{article}[11pt]

\usepackage{fullpage, amsmath, amssymb}

%% preamble
\newcommand{\fac}{\mathcal{F}}
\newcommand{\cli}{\mathcal{C}}
\newcommand{\PP}{\textsf{P}}
\newcommand{\NP}{\textsf{NP}}
\newcommand{\LP}{\text{LP}}
\newcommand{\DTIME}{\textsf{DTIME}}
\newcommand{\suchthat}{:}
\newcommand{\mydef}{\text{def}}
\newcommand{\wbar}{\overline}
\newcommand{\defeq}{\stackrel{\textbf{def}}{=}}
\newcommand{\etal}{et al.\ }
%% end preamble

\title{On the Approximation Algorithms for the Fault-tolerant Facility Location Problem\\(Research Proposal towards PhD Defense)}
\author{Li Yan\\Computer Science\\U of California Riverside}

\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
The Facility Location problem is a well-known problem in theoretical
computer science and operations research. The classic problem is the
uncapacilitated facility location problem (UFL). In the problem, we
are given a set of facilities $\fac$ and a set of clients $\cli$. Each
facility in $\fac$ has an opening cost $f_i$ and the connection cost
between a facility $i\in \fac$ and a client $j\in \cli$ is
$d_{ij}$. An algorithm needs to find a subset of $\fac$ to open and
connect every client to one of the open facilities.

A generalization of the UFL problem, is the Fault-tolerant Facility
Placement problem (FTFP), in which each client $j$ has demand $r_j$
and we now have sites, the set $\fac$ on which we can build
facilities. To open one facility at a site $i\in \fac$ incurs a cost
of $f_i$, and to connect one unit of demand from a client $j$ to a
facility $i$ incurs the connection cost $d_{ij}$. An algorithm needs
to open a number of facilities, possibly zero, on each site and
connect each of the $r_j$ demands of client $j$ to distinct
facilities. Facilities on the same site are considered different.

In the following we first review the related work in UFL, then we
discuss our result for FTFP, lastly we briefly describe some on-going
work and a plan towards the final defense.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Known Results for the Uncapacitated Facility
  Location problem}
It is easy to see that the UFL problem contains the Set Cover problem
as a special case. hence it is NP-hard and does not admit a polynomial
time algorithm with approximation ratio better than $(1-\epsilon)\ln
n$ for any constant $\epsilon >0$, unless $\NP \subseteq
\DTIME(n^{O(\log\log n)})$. On the other hand, Hochbaum showed that
the greedy algorithm which repeatedly picks the most cost-effective
star, consisting of one facility and a set of clients, achieved a
performance guarantee of $H_n = \ln + 1$. This shows that the lower
bound and upper bound of approximation ratio match for general
UFL~\footnote{Actually Neal showed an algorithm that achieves exactly
  $\ln n$-approximation.}. In the following we assume the connection
cost, or the distances $d_{ij}$ satisfy the triangle inequality, that
is, for any two facilities $i_1, i_2$ and two clients $j_1, j_2$, we
have $d_{i_1 j_2} \leq d_{i_1 j_1} + d_{i_2 j_1} + d_{i_2 j_2}$.

The metric UFL problem has been shown to be APX-hard and unless $\PP =
\NP$, there is no polynomial time algorithm giving approximation ratio
better than $1.463$~\footnote{Here $x=0.463$ is the root to equation
  $\ln (2/x) = 1+x$, and the implied lower bound is $1+x$.}.

There are a number of approximation algorithms progressing towards
this $1.463$ lower bound. The current best known approximation ratio
is $1.488$, using a combination of LP-rounding and greedy algorithms.
The algorithms can be classified into two categories: LP-rounding and
combinatorial. The LP-based algorithms require to solve the LP to
obtain a fractional optimal solution and then round it to an integral
solution. Combinatorial algorithms include primal-dual, greedy
analyzed with dual-fitting, local search.

\subsection{The LP-rounding Algorithms for UFL}
STA97 is the first paper achieving an $O(1)$-approximation ratio for
the UFL problem, and the clustering framework established in the same
paper underlies all subsequent LP-rounding algorithms.

Given a fractional optimal solution $(x_{ij}^\ast, y_i^\ast)$ to the
LP, we can first modify it to be \emph{complete}, that is
$x_{ij}^\ast>0$ implies $x_{ij}^\ast = y_i^\ast$ for all facility $i$
and client $j$.  

If all neighborhoods $N(j) = \{i\in\fac \suchthat x_{ij}^\ast > 0\}$
are disjoint, then we can open exactly one facility in each $N(j)$,
with each $i\in N(j)$ chosen with probability $y_i^\ast$. This will
give us expected facility cost $F^\ast$ and connection cost $C^\ast$.
However, in general those neighborhoods will overlap and we cannot
guarantee that every client $j$ has one of its neighbors open if we
open each facility $i$ independently with probability $y_i^\ast$. Now
the triangle inequality comes to help. If we guarantee a subset of
clients each having an open facility in its neighborhood, and for
every client $j$ outside this subset, it can find a client $j'$ in the
subset such that the distance $d_{j j'} \defeq \min_{i\in\fac} d_{ij}
+ d_{ij'}$ is not too large, then we can estimate the connection cost
of client $j$ by the sum of $d_{i' j'} + d_{j j'}$ where $i'$ is a
facility open in $N(j')$. In the literature, $j'$ is called a
\emph{center} and we say client $j$ is \emph{clustered} to center
$j'$. We also call $j'$ a \emph{primary} client and client $j$ is
\emph{assigned} to $j'$. Moreover, we would like to have all $j'$ in
the subset with disjoint $N(j')$ so that we could have a handle on the
facility cost.

The Shmoys, Tardos and Aardal's algorithm, referred below as STA97,
now becomes natural. Given a fractional optimal solution
$(x_{ij}^\ast, y_i^\ast)$, the algorithm first associate each client
$j$ with a value $g(j)$, which is essentially throw away all $i\in
N(j)$ with $d_{ij} > g(j)$. The modified neighborhood $\wbar
N(j)$ now satisfies $d_{ij} \leq g(j)$ for every $i\in \wbar
N(j)$. Now the algorithm works in iterations. In one iteration it
picks a non-clustered client with minimum $g(j)$, call it $p$, then
all remaining clients $j$ with $\wbar N(j)\cap \wbar N(p)$
non-empty will be added to the cluster centered at $p$. The iterations
completes when all clients are clustered. The next step is to open the
cheapest facility in each center's neighborhood and all clients
assigned to that cluster will connect to that facility.

To estimate the cost, it is easy to see the facility cost being
bounded by $F^\ast$, since neighborhood of centers are disjoint and we
effectively replacing a neighborhood with a minimum cost facility,
whose cost must be no more than the average cost of that
neighborhood. For connection cost, each center $p$ has connection cost
bounded by $g(p)$, while each non-center client $j$ has connection
cost bounded by the three edges $d_{i' p} + d_{ip} + d_{ij}$, where
$i'$ is the facility chosen in $\wbar N(p)$ and $i$ is any
facility in $\wbar N(p)\cap \wbar N(j)$. Because we can
upper bound the distance from a facility in $\wbar N(j)$ to $j$
by $g(j)$, we have that $d_{i' p} \leq g(p), d_{ip} \leq g(p)$ and
$d_{ij} \leq g(j)$. So for a non-center client, the distance is
bounded by $g(p) + g(p) + g(j) = 2g(p) + g(j) \leq 3g(j)$ since we
choose a center to minimize $g(p)$. Now we need to get a handle on
$g(j)$. To relate $g(j)$ to $C_j^\ast \defeq \sum_{i\in \fac}
d_{ij}x_{ij}^\ast$, we need to cut the neighborhood $N(j)$ by throwing
away some of the farthest facilities. Here are two ways, the STA97 way
and my way.

The STA97 does this by cutting at a distance $g(j)$, such that the
total connection value $x_{ij}^\ast$ for all $i\in N(j)$ with $d_{ij}
\leq g(j)$ accumulates to $1/\alpha$ for some constant $\alpha \geq 1$
to be fixed later. Let the modified neighborhood be $\wbar N(j)$. Now
the chosen part has total $x_{ij}^\ast$ at least $1/\alpha$, which
implies the other part has total $x_{ij}^\ast$ at most
$1-1/\alpha$. It follows that $g(j)*(1-1/\alpha) \leq \sum_{i\in N(j)}
d_{ij} x_{ij}^\ast = C_j^\ast$. So we have a bound on $g(j)$ in terms
of $C_j^\ast$ now. The rest is essentially adding up all clients so
that the connection cost is bounded by $\sum_{j\in\cli} 3g(j) =
3C^\ast/(1-1/\alpha)$. To compensate for cutting the total connection
value to $1/\alpha$, we need to scale up all $(x_{ij}^\ast, y_i^\ast)$
by $\alpha$. So our final ratio is $\max\{\alpha,
3/(1-1/\alpha)\}$. Pick $\alpha=4$ gives a $4$-approximation
algorithm.

A second way to cut is to use Markov bound. Instead of looking at
cumulative connection values, that is $x_{ij}^\ast$'s, we look
directly at the maximum distance from a sub-neighborhood. Now we cut
at $g(j) \leq \alpha\cdot C_j^\ast$ for every client $j$, so our
connection cost is now at most $\sum_{j\in\cli} 3g(j) \leq 3
\alpha\cdot C^\ast$. We need to estimate the total connection value
captured by that sub-neighborhood. And here is where Markov bound
comes in handy.  For random variable $X$ with mean $E[X]=\mu$, and a
number $t\geq 1$, we have
\begin{equation*}
  \text{Pr}(X \geq t\mu) \leq 1/t
\end{equation*}
Now plug in $g(j)$ for $x$, $C_j^\ast$ for $\mu$, and $\alpha$ for
$t$, we know that the total connection value outside the
sub-neighborhood is no more than $1/\alpha$, so the total connection
value inside the sub-neighborhood is at least $1-1/\alpha$. Again we
obtain the approximation ratio being $\max\{1/(1-1/\alpha),
3\alpha\}$, and take $\alpha = 4/3$ gives ratio $4$.

From there, the improvements by Chudak, Sviridenko and Byrka are
mostly on a better estimate on the connection cost of a non-primary
client, using randomized rounding.

Chudak noticed that $\alpha_j^\ast$, the dual solution, provided an
upper bound on $\max_{j\in N(j)} d_{ij}$. With a similar clustering,
the rounding process will open exactly one facility in each $N(p)$ but
randomly select a facility in $N(p)$ with probability
$y_{i}^\ast$. The facilities not in any $N(p)$ are then opened
independently with probability $y_i^\ast$. Now we can estimate the
distance by a provably worse process, which was then upper bounded by
$d_1 y_1 + d_2 y_2 (1-y_1) + \ldots + d_k y_k (1-y_1)\ldots(1-y_{k-1})
+ d_{k+1}(1-y_1)\ldots(1-y_k)$. This can be shown to imply a
connection cost no more than $C^\ast + 2/e \LP^\ast$. Together with
the expected facility cost being bounded by $F^\ast$, the total cost
is no more than $(1+2/e)\LP^\ast$.

Srividenko's improvement is to scale up all $y_i^\ast$ by some
constant $\alpha \geq 1$, then group clients with overlapping
$N_\alpha(j)$. A concave function was applied to estimate the
connection cost for each client and the fractional solution was
rounded by pairing up two fractional values and make at least one of
them being integral, 0 or 1. As the sum of those functions provides an
upper bound on the total cost and the value of that sum can only
decrease during the rounding process, it is sufficient to prove an
upper bound on the function value of the initial vector $(\bar y_i)$,
which was done by choosing carefully a distribution for $\alpha$ and
integrating the functions.

Byrka further developed Sviridenko and Chudak's idea with a better
estimate on the distance when all $N(j)$ are closed for a non-primary
client $j$. The exact derivation is a bit complicated but this allows
the ratio to be improved from $1.736$ to $1.575$. Following
Sviridenko's work, it is natural to expect that randomizing the
scaling factor $\alpha$ might lead to better approximation ratios, and
this has been done by Li (Princeton).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Greedy Algorithm for UFL with Dual-fitting Analysis}
The other related algorithm is a well-known heuristic, which greedily
picks up the most cost-effective star until all clients are
connected. A star $S$ consists of one facility and a set of
clients. The most cost effective star is the one with minimum average
cost, which is the sum of $f_i$ and $\sum_{j\in S} d_{ij}$, divided by
$|S|$, the number of clients in the star. 

Jain \etal showed the performance guarantee is no more than $1.81$,
using the dual-fitting technique. In the analysis, each client $j$ has
a number $\alpha_j$ associated with it. All $\alpha_j$ start with
$0$. Now the greedy algorithm can be reinterpreted as raising all
unconnected clients' $\alpha_j$ uniformly until some facility
accumulated a total payment of $f_i$, where payment is $\sum_{j\in U}
(\alpha_j - d_{ij})_+$, where $U$ is the set of unconnected
clients. Then facility $i$ is opened and all unconnected clients with
$\alpha_j \geq d_{ij}$ connect to $i$. Their $\alpha_j$'s are then
frozen. It is easy to see that the total cost of the algorithm is
equal to $\sum_{j\in\cli} \alpha_j$, however, those $\alpha_j$'s are
not a feasible dual solution in general, since the dual constraint
requires $\sum_{j\in \cli} (\alpha_j - d_{ij})_+ \leq f_i$. The next
job is to find a value $\gamma$, such that $\sum_{j\in \cli} (\alpha_j
/ \gamma - d_{ij})_+ \leq f_i$ for all facility $i$. A supremum of
$\gamma$ among all possible UFL instances is then an upper bound on
the approximation ratio of the greedy algorithm. Jain \etal showed
$\gamma$ is at most $1.81$. This is done by showing that any star in
any UFL instance is parameterized by $f_i, d_{ij}$ and $\alpha_j$ for
facility $i$ and clients $j$ in that star, and those parameters
satisfy certain inequalities. Those inequalities are used to upper
bound $\gamma$. The exact derivation is quite technical and not
elabrated here. There are two recent results on deriving the shrinking
factor $\gamma$ in a more systematic way, in STOC'11 and APPROX'12.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Preliminary Results for the Fault-tolerant Facility Placement
  Problem}
In this section we review the more general problem, FTFP, that we
studied extensively.

FTFP is easily seen as a generalization of UFL. In fact, a special
case, called uniform FTFP, where all demands $r_j$'s are equal, can be
solved by simple scaling and reduce to UFL, while preserving all
approximation ratios of UFL, hence is easy to approximate. In general,
$r_j$'s may be different and the non-uniform instances do not seem to
succumb to a simple scaling argument. Our effort is therefore along
two lines of attack: 1) LP-based rounding algorithms, and 2) Analyze
the greedy algorithm using dual-fitting technique or other
combinatorial argument without knowing the fractional optimal solution
to the LP.

For the LP-rounding algorithms, we show a technique to partition the
fractional optimal solution into another fractional solution that
specifies the fractional value of each individual demand of a client
to individual facilities created at each site. Then we were able to
show that the fractional solution obtained possess certain structural
properties that would allow us to employ known UFL rounding techniques
to deliver a feasible integral solution with approximation ratio
matching that of the corresponding algorithm for UFL. Specifically,
the best ratio we obtained is $1.575$~\footnote{1.575 is
  $\max\{\gamma, (1+1/e^\gamma)/(1-1/e^\gamma), 1+2/e^\gamma\}$.},
which matches the best ratio for UFL obtained using only LP-rounding.

For the greedy algorithm, we were able to show that: i) the algorithm does
run in polynomial time, and ii) the approximation ratio is no more
than $H_n$ where $n$ is the number of clients. Notice that this is the
same ratio as greedy for the Set Cover problem. Moreover, we show that
if we split cost of a star evenly between all participating clients,
then a simple example shows that the shrinking factor $\gamma$, needs
to be at least $H_n$. However, this does not imply the greedy
algorithm cannot give a constant ratio, nor does it assert the
algorithm cannot be analyzed using dual-fitting technique. For the
dual-fitting technique to be able to give an $O(1)$ ratio, we need a
charging scheme to distribute $f_i$, the facility opening cost of a
star to its member clients and our recent effort suggests that a local
charging scheme, that is, charge $f_i$ only to members of this star,
may not give a constant $\gamma$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{On-going Work and Expected Results}
It is in general difficult to predict progress and even the direction
of theoretical research. Our major effort currently is to show that
local charging cannot give a constant shrinking factor, thus providing
some negative argument against attempts showing greedy is actually an
$O(1)$-approximation algorithm.

The long term goal is, of course, showing that UFL actually has an
algorithm with approximation ratio $1.463$, matching the lower bound
known since 1998.

\end{document}
