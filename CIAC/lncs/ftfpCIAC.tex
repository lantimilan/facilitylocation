% camera ready version
% LNCS style 12 page limit
%
% CIAC submission
% lyan 2012-11-03 09:09:22
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass{llncs}

\usepackage{amssymb,enumerate}
\usepackage[nosumlimits]{amsmath}
\usepackage[nothing]{algorithm}
\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}

\floatname{algorithm}{Pseudocode}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\input{macros.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{LP-rounding Algorithms for the Fault-Tolerant\\
 		Facility Placement Problem (Extended Abstract)
		\thanks{Full version available in~\cite{YanC12}}
		}

              \author{Li Yan and Marek Chrobak}
              \institute{Department of Computer Science, University of California at Riverside\\
              \email{\{lyan,marek\}@cs.ucr.edu}}

\date{}

\begin{document}
\maketitle

\begin{abstract} 
  The Fault-Tolerant Facility Placement problem (FTFP) is a
  generalization of the classic Uncapacitated Facility Location
  Problem (UFL). In FTFP we are given a set of facility sites and a
  set of clients. Opening a facility at site $i$ costs $f_i$ and
  connecting client $j$ to a facility at site $i$ costs $d_{ij}$. We
  assume that the connection costs (distances) $d_{ij}$ satisfy the
  triangle inequality. Multiple facilities can be opened at any
  site. Each client $j$ has a demand $r_j$, which means that it needs
  to be connected to $r_j$ different facilities (some of which could
  be located on the same site). The goal is to minimize the sum of
  facility opening cost and connection cost. The main result of this
  paper is a $1.575$-approximation algorithm for FTFP, based on
  LP-rounding. The algorithm first reduces the demands to values
  polynomial in the number of sites. Then it uses a technique that we
  call adaptive partitioning, which splits clients into unit demands
   and appropriately partitions the
fractional solution. The partitioned solution satisfies properties
  which allow us to exploit existing LP-rounding methods for UFL to
  round our partitioned solution to an integral solution, preserving
  the approximation ratio. 
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% INTRODUCTION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

In the \emph{Fault-Tolerant Facility Placement} problem
(FTFP), we are given a set $\sitesset$ of \emph{sites} at
which facilities can be built, and a set $\clientset$ of
\emph{clients} with some demands that need to be satisfied
by different facilities. A client $j$ has demand
$r_j$. Building one facility at a site $i$ incurs a cost
$f_i$, and connecting one unit of demand from client $j$ to
a facility at site $i\in\sitesset$ costs $d_{ij}$.
We assume that the connection costs $d_{ij}$ are
symmetric and satisfy the triangle inequality. In a feasible solution, some
number of facilities, possibly zero, are opened at each site
$i$, and demands from each client are connected to those
open facilities, with the constraint that demands from the
same client have to be connected to different
facilities (possibly on the same site).

It is easy to see that if all $r_j=1$ then FTFP reduces to
the classic Uncapacitated Facility Location problem (UFL).
If we add a constraint that each site can have at most one
facility, then the problem is equivalent to the Fault-Tolerant Facility
Location problem (FTFL). Note that
in FTFL we have $\max_{j\in\clientset}r_j \leq |\sitesset|$, 
while in FTFP the values of $r_j$'s can be much bigger than $|\sitesset|$.

Great progress has been achieved lately in designing
approximation algorithms for UFL.
Shmoys~\etal~\cite{ShmoysTA97} proposed an approach based on
LP-rounding, achieving a ratio of 3.16.  This was then
improved by Chudak~\cite{ChudakS04} to 1.736, and later by
Sviridenko~\cite{Svi02} to 1.582.  Byrka~\cite{ByrkaA10}
gave an improved algorithm with ratio 1.5, by a combination of
LP-rounding with dual-fitting techniques.  Recently, Li~\cite{Li11} refined
the method from \cite{ByrkaA10} to obtain ratio 1.488, which is now
the best known approximation result for UFL. Other
techniques include the primal-dual algorithm by Jain and
Vazirani~\cite{JainV01}, the dual fitting method by
Jain~{\etal}~\cite{JainMMSV03}, and a local search heuristic
by Arya~{\etal}~\cite{AryaGKMMP04}.  On the hardness side,
it is known that it is not possible to approximate UFL in
polynomial time with ratio less than $1.463$, provided that
$\NP\not\subseteq\DTIME(n^{O(\log\log
  n)})$~\cite{GuhaK98}. An observation by Sviridenko
strengthened this assumption to $\PP\neq
\NP$~\cite{vygen05}.

FTFL was first introduced by Jain and
Vazirani~\cite{JainV03} who gave a primal-dual algorithm
with ratio $3\ln(\max_{j\in\clientset}r_j)$.  All
subsequently discovered constant-ratio approximation
algorithms use variations of LP-rounding, including the work
by Guha~{\etal}~\cite{GuhaMM01}, Swamy and
Shmoys~\cite{SwamyS08}, and Byrka~{\etal}~\cite{ByrkaSS10},
who improved the ratio to 1.7245, the best known
approximation ratio for FTFL.

FTFP is a natural generalization of UFL. It was first
studied by Xu and Shen~\cite{XuS09}, who presented an
approximation algorithm with a ratio claimed to be
$1.861$. However their algorithm runs in polynomial time
only if $\max_{j\in\clientset} r_j$ is polynomial in
$O(|\sitesset|\cdot |\clientset|)$ and their analysis of the
approximation ratio is flawed\footnote{Confirmed through
  private communication with the authors.}.  To date, the
best approximation ratio for FTFP is $3.16$ in~\cite{YanC11}, 
while the only known lower bound is the $1.463$ lower bound for UFL
from~\cite{GuhaK98}, that applies to FTFP.

\smallskip

The main result of this paper is an LP-rounding algorithm for FTFP
with approximation ratio 1.575, matching the best ratio for UFL
achieved via the LP-rounding method \cite{ByrkaGS10} and significantly
improving the bound in~\cite{YanC11}. In Section~\ref{sec: polynomial
  demands} we prove that, for the purpose of LP-based approximations,
we can assume that all demand values are polynomial in the number of
sites. This \emph{demand reduction} trick itself gives us ratio
$1.7245$, since we can then reduce the problem to
FTFL and use the algorithm from~\cite{ByrkaSS10}. It also ensures
that our algorithms run in polynomial time. If all demand values $r_j$
are equal, the problem can be solved by simple scaling and applying
LP-rounding algorithms for UFL. This does not affect the approximation
ratio, thus achieving ratio $1.575$ for this special case (see also
\cite{LiaoShen11}). In Section~\ref{sec: adaptive partitioning}, we
demonstrate a technique called \emph{adaptive partitioning}, which
splits clients into unit demands and partitions the optimal fractional
solution into a fractional solution of the split instance. By
exploiting structural properties of the partitioned solution we were
able to extend UFL rounding algorithms
in~\cite{gupta08,ChudakS04,ByrkaGS10}, retaining the approximation
ratio.

Summarizing, we show that the existing LP-rounding
algorithms for UFL can be extended to a much more general
problem FTFP. We believe
that, should even better LP-rounding algorithms be developed
for UFL, using our demand reduction and
adaptive partitioning methods, it should be possible to
extend them to FTFP.  In fact, some improvement of the ratio
can be achieved by randomizing the parameter
$\gamma$ used in Section~\ref{sec: 1.575-approximation}, as Li showed in \cite{Li11}
for UFL.  Our ratio of $1.575$ is significantly better
than the best ratio of $1.7245$ for the closely-related FTFL
problem. This suggests that in the fault-tolerant scenario
the capability of creating additional copies of facilities
makes the problem easier from the point of view of
approximation.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% LP ForMULATION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The LP Formulation}\label{sec: the lp formulation}

The FTFP problem has a natural Integer Programming (IP)
formulation. Let $y_i$ represent the number of facilities
built at site $i$ and let $x_{ij}$ represent the number of
connections from client $j$ to facilities at site $i$. If we
relax the integrality constraints, we obtain the following LP:

\noindent
\hspace{-0.1in}
\begin{minipage}{2.5in}
\begin{alignat}{3}
  &\textrm{min} &&\;\textstyle{\cost(\bfx,\bfy)} = \textstyle{ \sum_{i\in \sitesset}f_iy_i }
 		&&	+ \textstyle{ \sum_{i\in \sitesset, j\in \clientset}d_{ij}x_{ij} }  \label{eqn:fac_primal} 	
								\\ \notag
  &\textrm{s.t.} && y_i - x_{ij} \geq 0 &&  \forall i\in \sitesset, j\in \clientset 
									\\ \notag
  & &&\textstyle{\sum_{i\in \sitesset} x_{ij} \geq r_j} && \forall j\in \clientset
 									\\ \notag
  & &&\textstyle{ x_{ij} \geq 0, y_i \geq 0} && \forall i\in \sitesset, j\in \clientset 
  									\\ \notag
\end{alignat}
\end{minipage}
\hspace{0.01in}
\begin{minipage}{2in}
\begin{alignat}{3}
  &\textrm{max}&\quad& \textstyle{\sum_{j\in \clientset} r_j\alpha_j}\label{eqn:fac_dual}  
     						\\ \notag
  &\textrm{s.t.} && \textstyle{
    \sum_{j\in \clientset}\beta_{ij} \leq f_i}  &\quad& \forall i \in \sitesset  
							\\ \notag
  & &&\textstyle{\alpha_{j} - \beta_{ij} \leq
    d_{ij}}  && \forall i\in \sitesset, j\in \clientset 
							\\ \notag
  & &&\textstyle{\alpha_j \geq 0,
    \beta_{ij} \geq 0} && \forall i\in \sitesset, j\in \clientset
  							\\ \notag
\end{alignat}
\end{minipage}

In each of our algorithms we will fix some optimal solutions of the
LPs (\ref{eqn:fac_primal}) and (\ref{eqn:fac_dual}) that we will
denote by $(\bfx^\ast, \bfy^\ast)$ and $(\bfalpha^\ast,\bfbeta^\ast)$,
respectively. With $(\bfx^\ast, \bfy^\ast)$ fixed, we can define the
optimal facility cost as $F^\ast=\sum_{i\in\sitesset} f_i y_i^\ast$
and the optimal connection cost as $C^\ast =
\sum_{i\in\sitesset,j\in\clientset} d_{ij}x_{ij}^\ast$.  Then
$\LP^\ast = \cost(\bfx^\ast,\bfy^\ast) = F^\ast+C^\ast$ is the joint
optimal value of (\ref{eqn:fac_primal}) and (\ref{eqn:fac_dual}).  We
can also associate with each client $j$ its fractional connection cost
$C^\ast_j = \sum_{i\in\sitesset} d_{ij}x_{ij}^\ast$.  Clearly, $C^\ast
= \sum_{j\in\clientset} C^\ast_j$.  Throughout the paper we will use
notation $\OPT$ for the optimal integral solution of
(\ref{eqn:fac_primal}).  $\OPT$ is the value we wish to approximate,
but, since $\OPT\ge\LP^\ast$, we can instead use $\LP^\ast$ to
estimate the approximation ratio of our algorithms.

%%%%%%%%%

Define $(\bfx^\ast, \bfy^\ast)$ to be \emph{complete} if
$x_{ij}^\ast>0$ implies that $x_{ij}^\ast=y_i^\ast$ for all
$i,j$. In other words, each connection either uses a site
fully or not at all.  As shown by Chudak and
Shmoys~\cite{ChudakS04}, we can modify the given instance by
adding at most $|\clientset|$ sites to obtain an equivalent
instance that has a complete optimal solution.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% REDUCTION TO POLYNOMIAL DEMANDS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Reduction to Polynomial Demands}
\label{sec: polynomial demands}

This section presents a \emph{demand reduction} trick that
reduces the problem for arbitrary demands to a special case
where demands are bounded by $|\sitesset|$.
(The formal statement is a little more technical --
see Theorem~\ref{thm: reduction to polynomial}.) 

The reduction is based on a complete optimal fractional solution
$(\bfx^\ast,\bfy^\ast)$ of LP (\ref{eqn:fac_primal}). From the
optimality of this solution, we can also assume that
$\sum_{i\in\sitesset} x^\ast_{ij} = r_j$ for all
$j\in\clientset$.  As explained in Section~\ref{sec: the lp
  formulation}, we can assume that $(\bfx^\ast,\bfy^\ast)$
is complete, that is $x^\ast_{ij} > 0$ implies $x^\ast_{ij}
= y^\ast_i$ for all $i,j$.  We split this solution into two
parts, namely $(\bfx^\ast,\bfy^\ast) = (\hatbfx,\hatbfy)+
(\dotbfx,\dotbfy)$, where
%
$\haty_i \;\assign\; \floor{y_i^\ast}, \quad
			\hatx_{ij} \;\assign\; \floor{x_{ij}^\ast} \quad\textrm{and}\quad
\doty_i \;\assign\; y_i^\ast - \floor{y_i^\ast}, \quad
 	\dotx_{ij} \;\assign\; x_{ij}^\ast -  \floor{x_{ij}^\ast}
$
%
for all $i,j$. Now we construct two
FTFP instances $\hatcalI$ and $\dotcalI$ with the same
parameters as the original instance, except that the demand of each client $j$ is
$\hatr_j = \sum_{i\in\sitesset} \hatx_{ij}$ in instance $\hatcalI$ and
$\dotr_j = \sum_{i\in\sitesset} \dotx_{ij} = r_j - \hatr_j$ in instance $\dotcalI$. 
It is obvious that if we have integral solutions to both $\hatcalI$
and $\dotcalI$ then, when added together, they form an integral
solution to the original instance.  Moreover, we have the
following lemma.

%%%%%%%%%%

\begin{lemma}\label{lem: polynomial demands partition}
{\rm (i)}
  $(\hatbfx, \hatbfy)$ is a feasible integral solution to
  instance $\hatcalI$.

\noindent
{\rm (ii)}
  $(\dotbfx, \dotbfy)$ is a feasible fractional
  solution to instance $\dotcalI$.

\noindent
{\rm (iii)}
$\dotr_j\leq |\sitesset|$ for every client $j$.

\end{lemma}


%%%%%%%%%%%%%%%

\begin{theorem}\label{thm: reduction to polynomial}
  Suppose that there is a polynomial-time algorithm $\calA$
  that, for any instance of {\FTFP} with maximum demand
  bounded by $|\sitesset|$, computes an integral solution
  that approximates the fractional optimum of this instance
  within factor $\rho\geq 1$.  Then there is a
  $\rho$-approximation algorithm $\calA'$ for {\FTFP}.
\end{theorem}

%%%%%%%%%%%%%%%

\begin{proof}
  Algorithm~$\calA'$ solves the LP~(\ref{eqn:fac_primal}) to obtain a
  fractional optimal solution $(\bfx^\ast,\bfy^\ast)$, it constructs
  instances $\hatcalI$ and $\dotcalI$ described above,  applies
  algorithm~$\calA$ to $\dotcalI$, and finally adds 
 the integral solution $(\hatbfx, \hatbfy)$ of
  $\hatcalI$ and the integral solution of $\dotcalI$ produced
  by $\calA$. This produces a feasible integral
  solution for the original instance. The solution produced by 
$\calA$ has cost at most
$\rho\cdot\cost(\dotbfx,\dotbfy)$, because $(\dotbfx,\dotbfy)$
is feasible for $\dotcalI$. Thus the cost of $\calA'$ is at most
% 
$
 \cost(\hatbfx, \hatbfy) + \rho\cdot\cost(\dotbfx,\dotbfy)
	\le
 \rho(\cost(\hatbfx, \hatbfy) + \cost(\dotbfx,\dotbfy))
		= \rho\cdot\LP^\ast \le \rho\cdot\OPT
$. 
\qed
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ADAPTIVE PARTITION  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Adaptive Partitioning}
\label{sec: adaptive partitioning}

In this section we develop our second technique, which we
call \emph{adaptive partitioning}. Given an FTFP instance
and an optimal fractional solution $(\bfx^\ast, \bfy^\ast)$
to LP~(\ref{eqn:fac_primal}), we split each client $j$ into
$r_j$ individual \emph{unit demand points} (or just
\emph{demands}), and we split each site $i$ into no more
than $|\sitesset|+2R|\clientset|^2$ \emph{facility points}
(or \emph{facilities}), where
$R=\max_{j\in\clientset}r_j$. We denote the demand set by
$\demandset$ and the facility set by $\facilityset$,
respectively.  We will also partition
$(\bfx^\ast,\bfy^\ast)$ into a fractional solution
$(\barbfx,\barbfy)$ for the split instance.  We will
typically use symbols $\nu$ and $\mu$ to index demands and
facilities respectively, that is $\barbfx =
(\barx_{\mu\nu})$ and $\barbfy = (\bary_{\mu})$.  The
\emph{neighborhood of a demand} $\nu$ is
$\wbarN(\nu)=\braced{\mu\in\facilityset \suchthat
  \barx_{\mu\nu}>0}$.  We will use notation $\nu\in j$ to
mean that $\nu$ is a demand of client $j$; similarly,
$\mu\in i$ means that facility $\mu$ is on site
$i$. Different demands of the same client (that is,
$\nu,\nu'\in j$) are called \emph{siblings}.  Further, we
use the convention that $f_\mu = f_i$ for $\mu\in i$,
$\alpha_\nu^\ast = \alpha_j^\ast$ for $\nu\in j$ and
$d_{\mu\nu} = d_{\mu j} = d_{ij}$ for $\mu\in i$ and $\nu\in
j$.  We define $\concost_{\nu}
=\sum_{\mu\in\wbarN(\nu)}d_{\mu\nu}\barx_{\mu\nu} =
\sum_{\mu\in\facilityset}d_{\mu\nu}\barx_{\mu\nu}$.  One can
think of $\concost_{\nu}$ as the average connection cost of
demand $\nu$, if we chose a connection to facility $\mu$
with probability $\barx_{\mu\nu}$. In our partitioned
fractional solution we guarantee for every $\nu$ that
$\sum_{\mu\in\facilityset} \barx_{\mu\nu}=1$. Our partition
algorithm resembles superficially to the uncrossing
technique in Guha \etal's~\cite{GuhaMM03}
$O(1)$-approximation algorithm for FTFL, nonetheless our
construction and resulted structure is more delicate.

Some demands in $\demandset$ will be designated as
\emph{primary demands} and the set of primary demands will
be denoted by $P$. In addition, we will use the overlap
structure between demand neighborhoods to define a mapping
that assigns each demand $\nu\in\demandset$ to some primary
demand $\kappa\in P$. As shown in the rounding algorithms in
later sections, for each primary demand we guarantee exactly
one open facility in its neighborhood, while for a
non-primary demand we estimate its connection cost by the
distance to the facility opened by its assigned primary
demand. For this reason the connection cost of a primary
demand must be ``small'' compared to the non-primary demands
assigned to it. To have a bound on the facility cost, we can
think of the fractional $x_{ij}^\ast$ as the budget of how
much a client $j$ can use a site $i$, so (PS.\ref{PS:xij})
means all demands of a client $j$ together can only use as
much as $x_{ij}^\ast$. The reason we need (PS.\ref{PS:one})
is two-fold: (i) to have a proper distribution when select
one of facility in a primary demand's neighborhood and, (ii)
to obtain an estimate on the probability that none of a
demand's neighbor is open. We also need sibling demands
assigned to different primary demands to satisfy the
fault-tolerance requirement. Specifically, this partitioning
will be constructed to satisfy a number of properties that
are detailed below.
%
\begin{description}
	
      \renewcommand{\theenumii}{(\alph{enumii})}
      \renewcommand{\labelenumii}{\theenumii}

\item{(PS)} \emph{Partitioned solution}.
Vector $(\barbfx,\barbfy)$ is a partition of $(\bfx^\ast,\bfy^\ast)$, with unit-value
  demands, that is:

	\begin{enumerate}
		%
	\item \label{PS:one} 
          $\sum_{\mu\in\facilityset} \barx_{\mu\nu} = 1$ for each demand $\nu\in\demandset$. 
		%
	\item \label{PS:xij} $\sum_{\mu\in i, \nu\in j} \barx_{\mu\nu}
          = x^\ast_{ij}$ for each site $i\in\sitesset$ and client $j\in\clientset$.
		%
	\item \label{PS:yi}
          $\sum_{\mu\in i} \bary_{\mu} = y^\ast_i$ for each site $i\in\sitesset$.
		%
	\end{enumerate}
		
\item{(CO)} \emph{Completeness.}
	Solution   $(\barbfx,\barbfy)$ is complete, that is $\barx_{\mu\nu}\neq 0$ implies
				$\barx_{\mu\nu} = \bary_{\mu}$, for all $\mu\in\facilityset, \nu\in\demandset$.

\item{(PD)} \emph{Primary demands.}
	Primary demands satisfy the following conditions:

	\begin{enumerate}
		
	\item\label{PD:disjoint}  For any two different primary demands $\kappa,\kappa'\in P$ we have
				$\wbarN(\kappa)\cap \wbarN(\kappa') = \emptyset$.

	\item \label{PD:yi} For each site $i\in\sitesset$, 
		$ \sum_{\mu\in i}\sum_{\kappa\in P}\barx_{\mu\kappa} \leq y_i^\ast$.
		
	\item \label{PD:assign} Each demand $\nu\in\demandset$ is assigned
        to one primary demand $\kappa\in P$ such that

  			\begin{enumerate}
	
				\item \label{PD:assign:overlap} $\wbarN(\nu) \cap \wbarN(\kappa) \neq \emptyset$, and
				%
				\item \label{PD:assign:cost} $\concost_{\nu}+\alpha_{\nu}^\ast \geq
        			\concost_{\kappa}+\alpha_{\kappa}^\ast$.

			\end{enumerate}

	\end{enumerate}
	
\item{(SI)} \emph{Siblings}. For any pair $\nu,\nu'$ of different siblings we have
  \begin{enumerate}

	\item \label{SI:siblings disjoint}
		  $\wbarN(\nu)\cap \wbarN(\nu') = \emptyset$.
		
	\item \label{SI:primary disjoint} If $\nu$ is assigned to a primary demand $\kappa$ then
 		$\wbarN(\nu')\cap \wbarN(\kappa) = \emptyset$. In particular, by Property~(PD.\ref{PD:assign:overlap}),
		this implies that different sibling demands are assigned to different primary demands.

	\end{enumerate}
	
\end{description}

As we shall demonstrate in later sections, these properties allow us
to extend known UFL rounding algorithms to obtain an integral solution
to our FTFP problem with a matching approximation ratio. (For the
$1.575$-approximation algorithm in Section~\ref{sec:
  1.575-approximation}, these properties will need to be slightly
refined.)

%%%%%%%%%%%%%%%%

\myparagraph{Implementation of Adaptive Partitioning.}
 Recall that
$\facilityset$ and $\demandset$, respectively, denote the
sets of facilities and demands that will be created in this
stage, and $(\barbfx,\barbfy)$ is the partitioned solution
to be computed. 
The  partitioning algorithm consists of two phases:
Phase 1 is called the partition phase and Phase 2 is called
the augmenting phase. Phase 1 is done in iterations, where
in each iteration we find the ``best'' client $j$ and create a
new demand $\nu$ out of it. This demand either becomes a
primary demand itself, or it is assigned to some existing
primary demand. We call a client $j$ \emph{exhausted} when
all its $r_j$ demands have been created and assigned to some
primary demands. Phase 1 completes when all clients are
exhausted. In Phase 2 we ensure that every demand has a
total connection values equal to $1$, that is condition (PS.\ref{PS:one}).

For each site $i$ we will initially create one ``big"
facility $\mu$ with initial value $\bary_\mu = y^\ast_i$.
While we are partitioning the instance, creating new demands
and connections, this facility may end up being split into
more facilities to preserve completeness of the fractional
solution. Also, we will gradually decrease the fractional
connection vector for each client $j$, to account for the
demands already created for $j$ and their connection values.
These decreased connection values will be stored in an
auxiliary vector $\tildebfx$. The intuition is that
$\tildebfx$ represents the part of $\bfx^\ast$ that still
has not been allocated to existing demands and future
demands can use $\tildebfx$ for their connections. For
technical reasons, $\tildebfx$ will be indexed by facilities
(rather than sites) and clients, that is $\tildebfx =
(\tildex_{\mu j})$.  At the beginning, we set $\tildex_{\mu
  j}\assign x_{ij}^\ast$ for each $j\in\clientset$, where
$\mu\in i$ is the single facility created initially at site
$i$.  At each step, whenever we create a new demand $\nu$
for a client $j$, we will define its values $\barx_{\mu\nu}$
and appropriately reduce the values $\tildex_{\mu j}$, for
all facilities $\mu$. We will deal with two types of
neighborhoods, with respect to $\tildebfx$ and $\barbfx$,
that is $\wtildeN(j)=\{\mu\in\facilityset
\suchthat\tildex_{\mu j} > 0\}$ for $j\in\clientset$ and
$\wbarN(\nu)=\{\mu\in\facilityset \suchthat \barx_{\mu\nu}
>0\}$ for $\nu\in\demandset$.  During this process, the
following properties will hold for every facility $\mu$
after every iteration:
\begin{description}
\item (c1) For each demand $\nu$ either $\barx_{\mu\nu}=0$ or
  $\barx_{\mu\nu}=\bary_{\mu}$.
\item (c2) For each client $j$, either $\tildex_{\mu j}=0$ or
  $\tildex_{\mu j}=\bary_{\mu}$.
\end{description}
It may appear that (c1) is the same property as (CO), yet we repeat it
here as (c1) needs to hold after every iteration, while (CO) only
applies to the final partitioned fractional solution $(\barbfx,
\barbfy)$. A full description of the algorithm is given in
Pseudocode~\ref{alg:lpr2}.
%%%%%%%%%%%

\begin{algorithm}[ht]
  \caption{Algorithm: Adaptive Partitioning}
  \label{alg:lpr2}
  \begin{algorithmic}[1]
    \Require $\sitesset$, $\clientset$, $(\bfx^\ast,\bfy^\ast)$
    \Ensure  $\facilityset$,  $\demandset$, $(\barbfx, \barbfy)$ 
    \Comment Unspecified $\barx_{\mu \nu}$'s and $\tildex_{\mu j}$'s are assumed to be $0$

    \State $\tildebfr \assign \bfr, U\assign \clientset, \facilityset\assign \emptyset,
    \demandset\assign \emptyset, P\assign \emptyset$
    \Comment{Phase 1}

    \For{each site $i\in\sitesset$} 
    \State create a facility $\mu$ at $i$ and add $\mu$ to $\facilityset$,
    $\bary_\mu \assign y_i^\ast$ and $\tildex_{\mu j}\assign
    x_{ij}^\ast$ for each $j\in\clientset$ 
    \EndFor

    \While{$U\neq \emptyset$}
    \For{each $j\in U$}
    \State $\wtildeN_1(j) \assign {\NearestUnitChunk}(j, \facilityset, \tildebfx, \barbfx, \barbfy)$ \Comment see Pseudocode~\ref{alg:helper}
    \State $\tcc(j)\assign \sum_{\mu\in \wtildeN_1(j)} d_{{\mu}j}\cdot \tildex_{\mu j}$
    \EndFor
 
    \State $p \assign {\argmin}_{j\in U}\{ \tcc(j)+\alpha_j^\ast \}$
    \State create a new demand $\nu$ for client $p$

    \If{$\wtildeN_1 (p)\cap \wbarN(\kappa) \neq \emptyset$
      for some primary demand $\kappa\in P$}
    \State assign $\nu$ to $\kappa$,
    $\barx_{\mu \nu}\assign \tildex_{\mu p}$ and $\tildex_{\mu p}\assign 0$ for each $\mu \in \wtildeN(p) \cap \wbarN(\kappa)$
    \Else 
    \State make $\nu$ primary, $P \assign P \cup \{\nu\}$,
    set $\barx_{\mu\nu} \assign \tildex_{\mu p}$ and $\tildex_{\mu p}\assign 0$ for each $\mu\in \wtildeN_1(p)$

    \EndIf
    \State $\demandset\assign \demandset\cup \{\nu\},
    \tilder_p \assign \tilder_p -1$
	\State \textbf{if} {$\tilder_p=0$} \textbf{then} $U\assign U \setminus \{p\}$
    \EndWhile

    \For{each client $j\in\clientset$} \Comment{Phase 2}
    \For{each demand $\nu\in j$}    \Comment{each client $j$ has $r_j$ demands}
    \State \textbf{if} $\sum_{\mu\in \wbarN(\nu)}\barx_{\mu\nu}<1$
    \textbf{then} $\AugmentToUnit(\nu, j, \facilityset, \tildebfx, \barbfx, \barbfy)$ \Comment see Pseudocode~\ref{alg:helper}
    \EndFor
    \EndFor
  \end{algorithmic}
\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% subroutine: NearestUnitChunk and AugmentToUnit
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{algorithm}[ht]
  \caption{Helper functions used in Pseudocode~\ref{alg:lpr2}}
  \label{alg:helper}
  \begin{algorithmic}[1]
    \Function{\NearestUnitChunk}{$j, \facilityset, \tildebfx, \barbfx,\barbfy$}		
						\Comment upon return, $\sum_{\mu\in\wtildeN_1(j)} \tildex_{\mu j} = 1$
    \State Let $\wtildeN(j) = \{\mu_1,...,\mu_{q}\}$ where $d_{\mu_1 j} \leq d_{\mu_2 j} \leq \ldots \leq d_{\mu_{q j}}$
    \State Let $l$ be such that $\sum_{k=1}^{l} \bary_{\mu_k} \geq 1$ and $\sum_{k=1}^{l -1} \bary_{\mu_{k}} < 1$
    \State Create a new facility $\sigma$ at the same site as $\mu_l$ and add it to $\facilityset$
			\Comment split $\mu_l$
    \State Set $\bary_{\sigma}\assign \sum_{k=1}^{l} \bary_{\mu_{k}}-1$
					and $\bary_{\mu_l} \assign \bary_{\mu_l} - \bary_{\sigma}$
    \State For each $\nu\in\demandset$ with $\barx_{\mu_{l}\nu}>0$
 			set $\barx_{\mu_{l}\nu} \assign \bary_{\mu_l}$ and $\barx_{\sigma \nu} \assign \bary_{\sigma}$
    \State For each $j'\in\clientset$ with $\tildex_{\mu_{l} j'}>0$ (including $j$)
			set $\tildex_{\mu_l j'} \assign \bary_{\mu_l}$ and $\tildex_{\sigma j'} \assign \bary_\sigma$
	\State (All other new connection values are set to $0$)
    \State \Return $\wtildeN_1(j) = \{\mu_{1},\ldots,\mu_{l-1}, \mu_{l}\}$    				
    \EndFunction

    \Function{\AugmentToUnit}{$\nu, j, \facilityset, \tildebfx, \barbfx, \barbfy$}
    					\Comment $\nu$ is a demand of client $j$
    \While{$\sum_{\mu\in \facilityset} \barx_{\mu\nu} <1$}
    					\Comment upon return, $\sum_{\mu\in\wbarN(\nu)} \barx_{\mu\nu} = 1$
    \State Let $\eta$ be any facility such that $\tildex_{\eta j} > 0$
    \If{$1-\sum_{\mu\in \facilityset} \barx_{\mu\nu} \geq \tildex_{\eta j}$}
    \State $\barx_{\eta\nu} \assign \tildex_{\eta j}, \tildex_{\eta j} \assign 0$
    \Else
    \State Create a new facility $\sigma$ at the same site as $\eta$ and add it to $\facilityset$
    					\Comment split $\eta$
    \State Let $\bary_\sigma \assign 1-\sum_{\mu\in \facilityset} \barx_{\mu\nu}, \bary_{\eta} \assign \bary_{\eta} - \bary_{\sigma}$
    \State Set $\barx_{\sigma\nu}\assign \bary_{\sigma},\; \barx_{\eta \nu} \assign  0,\; \tildex_{\eta j} \assign \bary_{\eta}, \; \tildex_{\sigma j} \assign 0$
    \State For each $\nu' \neq \nu$ with $\barx_{\eta \nu'}>0$ set $\barx_{\eta \nu'} \assign \bary_{\eta},\; \barx_{\sigma \nu'} \assign \bary_{\sigma}$
    \State For each $j' \neq j$ with $\tildex_{\eta j'}>0$ set $\tildex_{\eta j'} \assign \bary_{\eta}, \tildex_{\sigma j'} \assign \bary_{\sigma}$
	\State  (All other new connection values are set to $0$)
    \EndIf
    \EndWhile
    \EndFunction
  \end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%


We start with $|\sitesset|$ facilities and in each iteration 
 each client causes at most one split.  We have at most
$R|\clientset|$ iterations as in each iteration we create one
demand. (Recall that $R = \max_jr_j$.) In Phase 2 the augmenting
operation creates no more than $R|\clientset|$ new facilities.  So the
total number of facilities will be at most $|\sitesset|+
R|\clientset|^2 + R|\clientset| \leq |\sitesset| + 2R|\clientset|^2$,
which is polynomial in $|\sitesset|+|\clientset|$ due to our bound on
$R$.

%%%%%%

\medskip

\emparagraph{Correctness.}  We now show that all the required
properties (PS), (CO), (PD) and (SI) are satisfied.  (CO) is implied
by the completeness condition (c1). (PS.\ref{PS:one}) is a result of
calling Procedure~$\AugmentToUnit()$ in Line~18. To see that
(PS.\ref{PS:xij}) holds, note that at each step the algorithm
maintains the invariant that, for every $i\in\sitesset$ and
$j\in\clientset$, we have $\sum_{\mu\in i}\sum_{\nu \in j} \barx_{\mu
  \nu} + \sum_{\mu\in i} \tildex_{\mu j} = x_{ij}^\ast$. In the end,
we will create $r_j$ demands for each client $j$, with each demand
$\nu\in j$ satisfying (PS.\ref{PS:one}), and hence $\sum_{\nu\in
  j}\sum_{\mu\in\facilityset}\barx_{\mu\nu}=r_j$.  As a result we have
$\tildex_{\mu j}=0$ for every facility $\mu\in\facilityset$, and
(PS.\ref{PS:xij}) follows.  (PS.\ref{PS:yi}) holds because every time
we split a facility $\mu$ into $\mu'$ and $\mu''$, the sum of
$\bary_{\mu'}$ and $\bary_{\mu''}$ is equal to the old value of
$\bary_{\mu}$.

Now we deal with properties in group (PD).  First,
(PD.\ref{PD:disjoint}) follows directly from the algorithm,
Pseudocode~\ref{alg:lpr2} (Line~13), since every primary demand has
its neighborhood fixed when created, and that neighborhood is disjoint
from those of the existing primary demands. Property (PD.\ref{PD:yi})
follows from (PD.\ref{PD:disjoint}), (CO) and (PS.\ref{PS:yi}). In
more detail, it can be justified as follows. By
(PD.\ref{PD:disjoint}), for each $\mu\in i$ there is at most one
$\kappa\in P$ with $\barx_{\mu\kappa} > 0$ and we have
$\barx_{\mu\kappa} = \bary_{\mu}$ due to (CO).  Let $K\subseteq i$ be
the set of those $\mu$'s for which such $\kappa\in P$ exists, and
denote this $\kappa$ by $\kappa_\mu$. Then, using conditions (CO) and
(PS.\ref{PS:yi}), we have $ \sum_{\mu\in i}\sum_{\kappa\in
  P}\barx_{\mu\kappa} = \sum_{\mu\in K}\barx_{\mu\kappa_\mu} =
\sum_{\mu\in K}\bary_{\mu} \leq \sum_{\mu\in i} \bary_{\mu} =
y_i^\ast$. Property (PD.\ref{PD:assign:overlap}) follows from the way
the algorithm assigns primary demands.  When demand $\nu$ of client
$p$ is assigned to a primary demand $\kappa$ in Line~11 of
Pseudocode~\ref{alg:lpr2}, we move all facilities in $\wtildeN(p)\cap
\wbarN(\kappa)$ (the intersection is nonempty) into $\wbarN(\nu)$, and
we never remove a facility from $\wbarN(\nu)$.  We postpone the proof
for (PD.\ref{PD:assign:cost}) to Lemma~\ref{lem: PD:assign:cost
  holds}.

Finally we argue that the properties in group (SI)
hold. (SI.\ref{SI:siblings disjoint}) is easy, since for any client
$j$, each facility $\mu$ is added to the neighborhood of at most one
demand $\nu\in j$, by setting $\barx_{\mu\nu}$ to $\bary_\mu$, while
other siblings $\nu'$ of $\nu$ have $\barx_{\mu\nu'}=0$. Note that
right after a demand $\nu\in p$ is created, its neighborhood is
disjoint from the neighborhood of $p$, that is $\wbarN(\nu)\cap
\wtildeN(p) = \emptyset$, by Line~11 of
Pseudocode~\ref{alg:lpr2}. Thus all demands of $p$ created later will
have neighborhoods disjoint from the set $\wbarN(\nu)$ before the
augmenting phase 2. Furthermore, Procedure~$\AugmentToUnit()$
preserves this property, because when it adds a facility to
$\wbarN(\nu)$ then it removes it from $\wtildeN(p)$, and in case of
splitting, one resulting facility is added to $\wbarN(\nu)$ and the
other to $\wtildeN(p)$. Property (SI.\ref{SI:primary disjoint}) is
shown below in Lemma~\ref{lem: property SI:primary disjoint holds}.

%%%%%%%

\begin{lemma}\label{lem: property SI:primary disjoint holds}
  Property~(SI.\ref{SI:primary disjoint}) holds after the
  Adaptive Partitioning stage.
\end{lemma}


%%%%%%%

We need one more lemma before proving our last property
(PD.\ref{PD:assign:cost}).  For a client $j$ and a demand
$\nu$, we use notation $\tcc_{\nu}(j)$ for the value of
$\tcc(j)$ at the time when $\nu$ was created. (It is not
necessary that $\nu\in j$ but we assume that $j$ is not
exhausted at that time.)


\begin{lemma}\label{lem: tcc optimal}
  Let $\eta$ and $\nu$ be two demands, with $\eta$ created no later
  than $\nu$, and let $j\in\clientset$ be a client that is not
  exhausted when $\nu$ is created. Then we have (a) $\tcc_\eta(j) \le
  \tcc_{\nu}(j)$, and (b) if $\nu\in j$ then $\tcc_\eta(j) \le
  \concost_{\nu}$.

\end{lemma}

%%%%%%%

\begin{lemma}\label{lem: PD:assign:cost holds}
Property~(PD.\ref{PD:assign:cost}) holds after the Adaptive Partitioning stage.
\end{lemma}

We have thus proved that properties (PS), (CO), (PD) and (SI) hold
for our partitioned solution $(\barbfx,\barbfy)$. In the
following sections we show how to use these properties to round the
fractional solution to an integral solution. 
(In the $1.575$-approximation in Section~\ref{sec:
  1.575-approximation}, this partitioning will need to be slightly
refined.)


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% 3-APPROXIMATION ALGORITHM %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Algorithm~{\EGUP} with Ratio $3$}
\label{sec: 3-approximation}

We first describe a simple algorithm that achieves ratio $3$. We use
this relatively simple algorithm to illustrate how the properties of
our partitioned fractional solution are used in rounding to obtain an
integral solution with cost close to an optimal solution. The rounding
approach is an extension to the method for UFL in~\cite{gupta08}.

\myparagraph{Algorithm~{\EGUP.}}  In Algorithm~{\EGUP}, we apply a
rounding process, guided by the fractional values $(\bary_{\mu})$ and
$(\barx_{\mu\nu})$, that produces an integral solution.  For each
primary demand $\kappa\in P$, we open one facility $\phi(\kappa) \in
\wbarN(\kappa)$. To this end, we use randomization: for each
$\mu\in\wbarN(\kappa)$, we choose $\phi(\kappa) = \mu$ with
probability $\barx_{\mu\kappa}$, ensuring that exactly one $\mu \in
\wbarN(\kappa)$ is chosen. Note that
$\sum_{\mu\in\wbarN(\kappa)}\barx_{\mu\kappa}=1$, so this distribution
is well-defined.  We open this facility $\phi(\kappa)$ and connect
$\kappa$ to this facility $\phi(\kappa)$, as well as all non-primary
demands that are assigned to $\kappa$.

In our description above, the algorithm is presented as a randomized
algorithm. It can be de-randomized using the method of conditional
expectations, standard enough that presenting it here would be
redundant. Readers less familiar with this field are recommended to
consult \cite{ChudakS04}.

%%%%%

\begin{lemma}\label{lemma:3fac}
  The expectation of facility cost $F_{\smallEGUP}$ of our solution is
  at most $F^\ast$.
\end{lemma}

%%%%%%%
\begin{lemma}\label{lemma:3dist}
The expectation of connection cost $C_{\smallEGUP}$ of our solution
is at most  $C^\ast+2\cdot\LP^\ast$.
\end{lemma}
%%%%%%%%%%
%%%%%%%%

\begin{theorem}
Algorithm~{\EGUP} is a $3$-approximation algorithm.
\end{theorem}

\begin{proof}
  By~(SI.\ref{SI:primary disjoint}), different
  demands from the same client are assigned to different
  primary demands, and by (PD.\ref{PD:disjoint}) each primary
  demand opens a different facility. This ensures that our
  solution is feasible, namely each client $j$ is connected
  to $r_j$ different facilities (some possibly located on
  the same site).  As for the total cost,
  Lemma~\ref{lemma:3fac} and Lemma~\ref{lemma:3dist} imply
  that the total cost is at most
  $F^\ast+C^\ast+2\cdot\LP^\ast = 3\cdot\LP^\ast \leq
  3\cdot\OPT$.
\qed
\end{proof}

%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% 1.736-APPROXIMATION ALGORITHM %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%\input{ECHS.tex}
\section{Algorithm~{\ECHS} with Ratio $1.736$}\label{sec: 1.736-approximation}

We now improve the approximation ratio to $1+2/e \approx
1.736$.  The facility opening cost of
Algorithm~{\EGUP} does not exceed that of the fractional optimum
solution, while the connection cost is quite far from the optimum,
since we estimate this cost using the
triangle inequality. The basic idea to improve this estimate,
following the approach of Chudak and
Shmoys~\cite{ChudakS04}, is to connect a non-primary demand to its
nearest neighbor when one is available and only use indirect connections
when none of its neighbor is open.

%%%%%%%%%%

\myparagraph{Algorithm~{\ECHS}.}  As before, the algorithm starts by
solving the linear program and applying the adaptive partitioning
algorithm described in Section~\ref{sec: adaptive partitioning} to
obtain a partitioned solution $(\barbfx, \barbfy)$. Then we apply the
rounding process to compute an integral solution (see
Pseudocode~\ref{alg:lpr3}).

%%%%%%%%%%%%%

\begin{algorithm}
  \caption{Algorithm~{\ECHS}:
    Constructing Integral Solution}
  \label{alg:lpr3}
  \begin{algorithmic}[1]
    \For{each $\kappa\in P$} 
    \State choose one $\phi(\kappa)\in \wbarN(\kappa)$,
    with each $\mu\in\wbarN(\kappa)$ chosen as $\phi(\kappa)$
    with probability $\bary_\mu$ (note {$\barx_{\mu\kappa} =
      \bary_{\mu}$ for all $\mu \in \wbarN(\kappa)$})
    \State open $\phi(\kappa)$ and connect $\kappa$ to $\phi(\kappa)$
    \EndFor
    \For{each $\mu\in\facilityset - \bigcup_{\kappa\in P}\wbarN(\kappa)$} 
    \State open $\mu$ with probability $\bary_\mu$ (independently)
    \EndFor
    \For{each non-primary demand $\nu\in\demandset$}
    \If{any facility in $\wbarN(\nu)$ is open}
    \State{connect $\nu$ to the nearest open facility in $\wbarN(\nu)$}
    \Else
    \State connect $\nu$ to $\phi(\kappa)$ where $\kappa$ is $\nu$'s
     primary demand
    \EndIf
    \EndFor
  \end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%

\myparagraph{Analysis.}
We first show feasibility.
The only constraint that is not explicitly
enforced by the algorithm is the fault-tolerance requirement; namely
that each client $j$ is connected to $r_j$ different facilities. Let
$\nu$ and $\nu'$ be two different sibling demands of client $j$ and
let their assigned primary demands be $\kappa$ and $\kappa'$
respectively. Due to (SI.\ref{SI:primary disjoint}) we know $\kappa
\neq \kappa'$. From (SI.\ref{SI:siblings disjoint}) we have
$\wbarN(\nu) \cap \wbarN(\nu') = \emptyset$. From (SI.\ref{SI:primary
  disjoint}), we have $\wbarN(\nu) \cap \wbarN(\kappa') = \emptyset$
and $\wbarN(\nu') \cap \wbarN(\kappa) = \emptyset$. From
(PD.\ref{PD:disjoint}) we have $\wbarN(\kappa)\cap \wbarN(\kappa') =
\emptyset$. It follows that $(\wbarN(\nu) \cup \wbarN(\kappa)) \cap
(\wbarN(\nu') \cup \wbarN(\kappa')) = \emptyset$. Since the algorithm
connects $\nu$ to some facility in $\wbarN(\nu) \cup \wbarN(\kappa)$
and $\nu'$ to some facility in $\wbarN(\nu') \cup \wbarN(\kappa')$,
$\nu$ and $\nu'$ will be connected to different facilities. 

This integral solution can be shown to have expected facility cost
bounded by $F^\ast$ and connection cost bounded by $C^\ast +
(2/e)\cdot \LP^\ast$ As a result the expected total cost is bounded by
$(1 + 2/e)\cdot \LP^\ast$. We state this as the theorem below.
\begin{theorem}\label{thm:1736}
  Algorithm~{\ECHS} is a $(1+2/e)$-approximation algorithm for \FTFP.
\end{theorem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Byrka 2010 1.575
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%\input{EBGS.tex}
%% NEW VERSION

\section{Algorithm~{\EBGS} with Ratio $1.575$}\label{sec: 1.575-approximation}

In this section we give our main result, a $1.575$-approximation
algorithm for $\FTFP$, where $1.575$ is the rounded value of $\min_{\gamma\geq
  1}\max\{\gamma, 1+2/e^\gamma, \frac{1/e+1/e^\gamma}{1-1/\gamma}\}$.
 This matches the ratio of the best
known LP-rounding algorithm for UFL by
Byrka~{\etal}~\cite{ByrkaGS10}. Recall that in Section~\ref{sec:
  1.736-approximation} we showed how to compute an integral solution
with facility cost bounded by $F^\ast$ and connection cost bounded by
$C^\ast + 2/e\cdot\LP^\ast$. A natural idea is to balance these two
costs, by reducing the connection cost, at the expense of slightly
increasing the facility cost.

Our approach is a combination of the ideas
in~\cite{ByrkaGS10} with the techniques of demand reduction and
adaptive partitioning that we introduced earlier. However, our
adaptive partitioning technique needs to be carefully modified because
now we will be using a more intricate neighborhood structure, with the
neighborhood of each demand divided into two parts, the close and far
neighborhood, and with some conditions on which pairs of neighborhoods
need to overlap and which need to be disjoint. The final rounding
stage that construct an integral solution is a relatively
straightforward generalization of the rounding method in
\cite{ByrkaGS10}.

We begin by describing properties that our partitioned fractional
solution $(\barbfx,\barbfy)$ needs to satisfy. The neighborhood
$\wbarN(\nu)$ of each demand $\nu$ will be divided into two disjoint
parts.  The first part, called the \emph{close neighborhood}
$\wbarclsnb(\nu)$, contains the facilities in $\wbarN(\nu)$ nearest to
$\nu$ with the total connection value equal $1/\gamma$. The second
part, called the \emph{far neighborhood} $\wbarfarnb(\nu)$, contains
the remaining facilities in $\wbarN(\nu)$. The formal definitions of
these sets are given below in Property~(NB).  The respective average
connection costs from $\nu$ for these sets are defined by
$\clsdist(\nu)=\gamma\sum_{\mu\in\wbarclsnb(\nu)}
d_{\mu\nu}\barx_{\mu\nu}$ and
$\fardist(\nu)=\frac{\gamma}{\gamma-1}\sum_{\mu\in\wbarfarnb(\nu)}
d_{\mu\nu}\barx_{\mu\nu}$. We will also use notation
$\clsmax(\nu)=\max_{\mu\in\wbarclsnb(\nu)} d_{\mu\nu}$ for the maximum
distance from $\nu$ to its close neighborhood.

Our partitioned solution $(\barbfx,\barbfy)$ must satisfy the same
partitioning and completeness properties as before, namely properties
(PS) and (CO) in Section~\ref{sec: adaptive partitioning}.  In
addition, it must satisfy new neighborhood property (NB) and modified
properties (PD') and (SI'), listed below.

\begin{description}
	
      \renewcommand{\theenumii}{(\alph{enumii})}
      \renewcommand{\labelenumii}{\theenumii}

\item{(NB)} \label{NB}
	For each demand $\nu$, its neighborhood is divided into \emph{close} and
	\emph{far} neighborhood, that is $\wbarN(\nu) = \wbarclsnb(\nu) \cup \wbarfarnb(\nu)$, where
	%
	\begin{itemize}
	\item $\wbarclsnb(\nu) \cap \wbarfarnb(\nu) = \emptyset$,
	\item $\sum_{\mu\in\wbarclsnb(\nu)} \barx_{\mu\nu} =1/\gamma$, and 
	\item if $\mu\in \wbarclsnb(\nu)$ and $\mu'\in \wbarfarnb(\nu)$ 
				then $d_{\mu\nu}\le d_{\mu'\nu}$.   
	\end{itemize}
	%
	Note that the second condition, together with (PS.\ref{PS:one}), implies
	that $\sum_{\mu\in\wbarfarnb(\nu)} \barx_{\mu\nu} =1-1/\gamma$.

\item{(PD')} \emph{Primary demands.}
	Primary demands satisfy the following conditions:

	\begin{enumerate}
		
	\item\label{PD1:disjoint}  For any two different primary demands $\kappa,\kappa'\in P$ we have
				$\wbarclsnb(\kappa)\cap \wbarclsnb(\kappa') = \emptyset$.

	\item \label{PD1:yi} For each site $i\in\sitesset$, 
		$ \sum_{\kappa\in P}\sum_{\mu\in i\cap\wbarclsnb(\kappa)}\barx_{\mu\kappa} \leq y_i^\ast$.
		
	\item \label{PD1:assign} Each demand $\nu\in\demandset$ is assigned
        to one primary demand $\kappa\in P$ such that

  			\begin{enumerate}
	
				\item \label{PD1:assign:overlap} $\wbarclsnb(\nu) \cap \wbarclsnb(\kappa) \neq \emptyset$, and
				%
				\item \label{PD1:assign:cost}
          $\clsdist(\nu)+\clsmax(\nu) \geq
          \clsdist(\kappa)+\clsmax(\kappa)$.
          %
			\end{enumerate}

	\end{enumerate}
	
\item{(SI')} \emph{Siblings}. For any pair $\nu,\nu'$ of different siblings we have
  \begin{enumerate}

	\item \label{SI1:siblings disjoint}
		  $\wbarN(\nu)\cap \wbarN(\nu') = \emptyset$.
		
	\item \label{SI1:primary disjoint} If $\nu$ is assigned to a primary demand $\kappa$ then
 		$\wbarN(\nu')\cap \wbarclsnb(\kappa) = \emptyset$. In particular, by Property~(PD.\ref{PD1:assign:overlap}),
		this implies that different sibling demands are assigned to different primary demands.

	\end{enumerate}
	
\end{description}

%%%%%%%%%%%%%%%%%

\myparagraph{Modified adaptive partitioning.}
 As in Section~\ref{sec: adaptive partitioning}, our modified partitioning algorithm
has two phases.
In Phase~1 we split clients into demands and create facilities on
sites, while in Phase~2 we augment each demand's
connection values so that its total value is $1$.

Phase~1 runs in iterations. Consider any client $j$.  As before,
$\wtildeN(j)$ is the neighborhood of $j$ with respect to the yet
unpartitioned solution, namely the set of facilities $\mu$ such that
$\tildex_{\mu j}>0$. Order the facilities in this set as
$\wtildeN(j) = \braced{\mu_1,...,\mu_q}$ in order of non-decreasing
distance from $j$, that is
$d_{\mu_1 j} \leq d_{\mu_2 j} \leq \ldots \leq d_{\mu_q j}$, where
$q = |\wtildeN(j)|$. Without loss of generality, there is an index
$l$ for which $\sum_{s=1}^l \tildex_{s j} = 1/\gamma$, since we can
always split one facility to have this property. Then we define
$\wtildeN_{\gamma}(j) = \braced{\mu_1,...,\mu_l}$. We also use notation
%
$
\tcc_\gamma(j) =  D(\wtildeN_\gamma(j), j) = \sum_{\mu\in\wtildeN_{\gamma}(j)} d_{\mu j} \tildex_{\mu j}
			\quad\textrm{ and }\quad
 \dmax_\gamma(j) = \max_{\mu \in \wtildeN_{\gamma}(j)} d_{\mu j}
$.
%
In each iteration, we find a not yet exhausted client $p$ that minimizes the
value of $\tcc_\gamma(p) + \dmax_\gamma(p)$. Now we have two cases:

\smallskip
\noindent
{\mycase{1}} $\wtildeN_{\gamma}(p) \cap
  \wbarclsnb(\kappa)\neq\emptyset$, for some existing primary demand
  $\kappa$.  In this case we assign $\nu$ to $\kappa$. As before, if
  there are multiple such $\kappa$, we pick any of them. We also fix
  $\barx_{\mu \nu} \assign \tildex_{\mu p}, \tildex_{\mu p}\assign 0$
  for each $\mu \in \wtildeN(p)\cap \wbarclsnb(\kappa)$. As before,
  although we check for overlap between $\wtildeN_{\gamma}(p)$ and
  $\wbarclsnb(\kappa)$, the facilities we actually move into
  $\wbarN(\nu)$ include all facilities in the intersection of
  $\wtildeN(p)$, a bigger set, with $\wbarclsnb(\kappa)$. We would
  like to point out that $\wbarN(\nu)$ is not finalized at this time
  as we will add more facilities to it in the augment phase. As a
  result $\wbarclsnb(\nu)$ is not fixed either, as we could
  potentially add facilities closer to $\nu$ than facilities already
  in $\wbarN(\nu)$.

\smallskip
\noindent
{\mycase{2}} $\wtildeN_{\gamma}(p) \cap \wbarclsnb(\kappa) =
  \emptyset$, for all existing primary demands $\kappa$.  In this case
  we make $\nu$ a primary demand. We then fix $\barx_{\mu \nu}\assign
  \tildex_{\mu p}$ for $\mu \in \wtildeN_{\gamma}(p)$ and set the
  corresponding $\tildex_{\mu p}$ to $0$.  Note that the total
  connection value in $\wbarclsnb(\nu)$ is now exactly $1/\gamma$.
  The set $\wtildeN_{\gamma}(p)$ turns out to coincide with
  $\wbarclsnb(\nu)$ as the facilities in $\wtildeN(p) \setminus
  \wtildeN_{\gamma}(p)$ are all farther away than any facilitity in
  $\wtildeN_{\gamma}(p)$. In the augmenting phase, Phase 2, we have
  available only facilities in some subset of $\wtildeN(p) \setminus
  \wtildeN_{\gamma}(p)$. Thus $\wbarclsnb(\nu)$ is defined when $\nu$
  is created.

\smallskip

Once all clients are exhausted, that is, each client $j$ has $r_j$
demands created, Phase~1 concludes. We then do Phase~2, the augmenting
phase.  For each demand $\nu$ of client $j$ with total connection
value less than $1$, we use our $\AugmentToUnit()$ procedure to add
additional facilities from $\wtildeN(j)$ to $\nu$'s neighborhood to
make its total connection value equal $1$, as before a facility is
removed from $\wtildeN(j)$ once added to a demand's neighborhood. We
do facility split if necessary to make $\wbarN(\nu)$ have total
connection value of 1.  

\smallskip

We argue that the fractional solution $(\barbfx,\barbfy)$
satisfies all the stated properties. Properties~(PS), (CO), (NB),
(PD'.\ref{PD1:disjoint}) and (SI'.\ref{SI1:siblings disjoint}) are
enforced by the algorithm. The proofs
for other properties (PD'.\ref{PD1:yi}), (PD'.\ref{PD1:assign:cost})
and (SI'.\ref{SI1:primary disjoint}) are similar to those in
Section~\ref{sec: adaptive partitioning}, with the exception of
(PD.\ref{PD:assign:overlap}), which we justify below.

The argument for (PD.\ref{PD:assign:overlap}) is a bit subtle, because
of complications arising in Phase 2.  This phase does not change close
neighborhoods of primary demands, as each primary demand already
contains all the nearest facilities with total connection value equal
$1/\gamma$.  For non-primary demands, however, $\wbarN(\nu)$, for
$\nu\in j$, takes all facilities in $\wbarclsnb(\kappa)\cap
\wtildeN(j)$, which might be close to $\kappa$ but far from $j$.  As a
result, facilities added in the augmenting phase might appear in
$\wbarclsnb(\nu)$, yet they are not in $\wbarclsnb(\kappa)$, the close
neighborhood of the primary demand $\kappa$ that $\nu$ is assigned
to. It is conceivable that in a worst case, the facilities added in
the augmenting phase form $\wbarclsnb(\nu)$ exclusively, which will
then be disjoint from $\wbarclsnb(\kappa)$, and we may not have
(PD.\ref{PD:assign:overlap}) for demand $\nu$. Nevertheless, we show
that Property~(PD.\ref{PD:assign:overlap}) holds.

Consider an iteration when we create a demand $\nu\in p$
and assign it to $\kappa$. Then the set
$B(p)=\wtildeN_{\gamma}(p)\cap \wbarclsnb(\kappa)$ is not empty.
We claim that
$B(p)$ must be a subset of $\wbarclsnb(\nu)$ after $\wbarN(\nu)$ is
finalized with a total connection value of $1$. To see this, first
observe that $B(p)$ is a subset of $\wbarN(\nu)$, which in turn is a
subset of $\wtildeN(p)$, after taking into account the facility
split. Here $\wtildeN(p)$ refers to the neighborhood of client $p$
just before $\nu$ was created. For an arbitrary set of facilities
$A$ define $\dmax(A, \nu)$ as the minimum distance $\tau$ such
that $\sum_{\mu\in A \suchthat d_{\mu\nu} \leq \tau}\;\bary_{\mu} \geq
1/\gamma$.
Adding additional facilities into $A$ cannot make
$\dmax(A, \nu)$ larger, so it follows that $\dmax(\wbarclsnb(\nu), \nu)
\geq \dmax(\wtildeN(p), \nu)$, because $\wbarclsnb(\nu)$ is a subset of
$\wtildeN(p)$. Since we have $d_{\mu \nu} = d_{\mu p}$ by definition,
it is easy to see that every $\mu \in B(p)$ satisfies $d_{\mu \nu}
\leq \dmax(\wtildeN(p), \nu) \leq \dmax(\wbarclsnb(\nu), \nu)$ and
hence they all belong to $\wbarclsnb(\nu)$. We need to be a bit more
careful here when we have a tie in $d_{\mu\nu}$ but we can assume ties
are always broken in favor of facilities in $B(p)$ when defining
$\wbarclsnb(\nu)$. Finally, since $B(p)\neq\emptyset$, we have that the
close neighborhood of a demand $\nu$ and its primary demand $\kappa$
must overlap.

%%%%%%%%

\myparagraph{Algorithm~{\EBGS}.}
The complete algorithm starts with solving the linear program and
computing the partitioning described earlier in this section.
Given the partitioned fractional solution $(\barbfx,
\barbfy)$ with the desired properties, we then start opening
facilities and making connections to obtain an integral
solution. As before, we open exactly one facility in each
cluster (the close neighborhood of a primary demand), but
now each facility $\mu$ is chosen with probability
$\gamma\bary_{\mu}$. The non-clusterd facilities $\mu$,
those that do not belong to $\wbarN_{\cls}(\kappa)$ for any
primary demand $\kappa$, are opened independently with
probability $\gamma\bary_{\mu}$ each. 

Next, we connect demands to facilities.  Each primary demand $\kappa$
will connect to the only facility $\phi(\kappa)$ open in its cluster
$\wbarclsnb(\kappa)$.  For each non-primary demand $\nu$, if there is
an open facility in $\wbarN(\nu)$ then we connect $\nu$ to the nearest
such facility. Otherwise, we connect $\nu$ to its \emph{target
  facility} $\phi(\kappa)$, where $\kappa$ is the primary demand that
$\nu$ is assigned to.

%%%%%%%%%%%

\myparagraph{Analysis.}
The feasibility of our integral solution follows from
Properties~(SI.\ref{SI1:siblings disjoint}), (SI.\ref{SI1:primary
  disjoint}), and (PD.\ref{PD1:disjoint}), as these properties together
ensure that each facility is accessible to at most one demand among
sibling demands of the same client, regardless whether a demand
connects to its neighbor or its target facility.

The expected facility cost of our algorithm is bounded by $\gamma
F^\ast$, using essentially the same argument as in the previous
section (with the the factor $\gamma$ accounting for using
probabilities $\gamma \bary_{\mu}$ instead of $\bary_{\mu}$).  It is
also possible to show that the expected connection cost can be bounded
by $C^\ast \max\{\frac{1/e+1/e^\gamma}{1-1/\gamma},
1+\frac{2}{e^\gamma}\}$.Hence the total cost is bounded by
$\max\{\gamma, \frac{1/e+1/e^\gamma}{1-1/\gamma},
1+\frac{2}{e^\gamma}\}\cdot \LP^\ast$. Picking $\gamma=1.575$ we
obtain:

\begin{theorem}\label{thm:ebgs}
  Algorithm~{\EBGS} is a $1.575$-approximation algorithm for \FTFP.
\end{theorem}


%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{plain}
\bibliography{facility}

\end{document}
